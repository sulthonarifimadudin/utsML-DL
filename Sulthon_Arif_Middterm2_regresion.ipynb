{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q gdown\n",
        "!gdown --folder 1wR-R5tBUZvnCl4N0iTzm2z04umuW9Jw-"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSORq4ye_o-K",
        "outputId": "ccd77974-6c97-40e6-d10c-f58aa037dba2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieving folder contents\n",
            "Processing file 13WrJHaXyxg0RdhpvF3rIo_6UXOm68FYw midterm-regresi-dataset.csv\n",
            "Retrieving folder contents completed\n",
            "Building directory structure\n",
            "Building directory structure completed\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=13WrJHaXyxg0RdhpvF3rIo_6UXOm68FYw\n",
            "From (redirected): https://drive.google.com/uc?id=13WrJHaXyxg0RdhpvF3rIo_6UXOm68FYw&confirm=t&uuid=f5298c34-906d-40f5-a5cb-4d62be2d6abd\n",
            "To: /content/Middterm2/midterm-regresi-dataset.csv\n",
            "100% 443M/443M [00:03<00:00, 122MB/s]\n",
            "Download completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "id": "arhfrhqBDyTh",
        "outputId": "3b84752e-6fdb-43f8-b6fb-2d2d22ded390"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   2001  49.94357  21.47114   73.0775   8.74861  -17.40628  -13.09905  \\\n",
              "0  2001  48.73215  18.42930  70.32679  12.94636  -10.32437  -24.83777   \n",
              "1  2001  50.95714  31.85602  55.81851  13.41693   -6.57898  -18.54940   \n",
              "2  2001  48.24750  -1.89837  36.29772   2.58776    0.97170  -26.21683   \n",
              "3  2001  50.97020  42.20998  67.09964   8.46791  -15.85279  -16.81409   \n",
              "4  2001  50.54767   0.31568  92.35066  22.38696  -25.51870  -19.04928   \n",
              "\n",
              "   -25.01202  -12.23257   7.83089  ...   13.0162  -54.40548  58.99367  \\\n",
              "0    8.76630   -0.92019  18.76548  ...   5.66812  -19.68073  33.04964   \n",
              "1   -3.27872   -2.35035  16.07017  ...   3.03800   26.05866 -50.92779   \n",
              "2    5.05097  -10.34124   3.55005  ...  34.57337 -171.70734 -16.96705   \n",
              "3  -12.48207   -9.37636  12.63699  ...   9.92661  -55.95724  64.92712   \n",
              "4   20.67345   -5.19943   3.63566  ...   6.59753  -50.69577  26.02574   \n",
              "\n",
              "   15.37344   1.11144  -23.08793   68.40795  -1.82223  -27.46348   2.26327  \n",
              "0  42.87836  -9.90378  -32.22788   70.49388  12.04941   58.43453  26.92061  \n",
              "1  10.93792  -0.07568   43.20130 -115.00698  -0.05859   39.67068  -0.66345  \n",
              "2 -46.67617 -12.51516   82.58061  -72.08993   9.90558  199.62971  18.85382  \n",
              "3 -17.72522  -1.49237   -7.50035   51.76631   7.88713   55.66926  28.74903  \n",
              "4  18.94430  -0.33730    6.09352   35.18381   5.00283  -11.02257   0.02263  \n",
              "\n",
              "[5 rows x 91 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-087d47b1-0163-45f1-9a2f-aeb179822744\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>2001</th>\n",
              "      <th>49.94357</th>\n",
              "      <th>21.47114</th>\n",
              "      <th>73.0775</th>\n",
              "      <th>8.74861</th>\n",
              "      <th>-17.40628</th>\n",
              "      <th>-13.09905</th>\n",
              "      <th>-25.01202</th>\n",
              "      <th>-12.23257</th>\n",
              "      <th>7.83089</th>\n",
              "      <th>...</th>\n",
              "      <th>13.0162</th>\n",
              "      <th>-54.40548</th>\n",
              "      <th>58.99367</th>\n",
              "      <th>15.37344</th>\n",
              "      <th>1.11144</th>\n",
              "      <th>-23.08793</th>\n",
              "      <th>68.40795</th>\n",
              "      <th>-1.82223</th>\n",
              "      <th>-27.46348</th>\n",
              "      <th>2.26327</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.73215</td>\n",
              "      <td>18.42930</td>\n",
              "      <td>70.32679</td>\n",
              "      <td>12.94636</td>\n",
              "      <td>-10.32437</td>\n",
              "      <td>-24.83777</td>\n",
              "      <td>8.76630</td>\n",
              "      <td>-0.92019</td>\n",
              "      <td>18.76548</td>\n",
              "      <td>...</td>\n",
              "      <td>5.66812</td>\n",
              "      <td>-19.68073</td>\n",
              "      <td>33.04964</td>\n",
              "      <td>42.87836</td>\n",
              "      <td>-9.90378</td>\n",
              "      <td>-32.22788</td>\n",
              "      <td>70.49388</td>\n",
              "      <td>12.04941</td>\n",
              "      <td>58.43453</td>\n",
              "      <td>26.92061</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.95714</td>\n",
              "      <td>31.85602</td>\n",
              "      <td>55.81851</td>\n",
              "      <td>13.41693</td>\n",
              "      <td>-6.57898</td>\n",
              "      <td>-18.54940</td>\n",
              "      <td>-3.27872</td>\n",
              "      <td>-2.35035</td>\n",
              "      <td>16.07017</td>\n",
              "      <td>...</td>\n",
              "      <td>3.03800</td>\n",
              "      <td>26.05866</td>\n",
              "      <td>-50.92779</td>\n",
              "      <td>10.93792</td>\n",
              "      <td>-0.07568</td>\n",
              "      <td>43.20130</td>\n",
              "      <td>-115.00698</td>\n",
              "      <td>-0.05859</td>\n",
              "      <td>39.67068</td>\n",
              "      <td>-0.66345</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2001</td>\n",
              "      <td>48.24750</td>\n",
              "      <td>-1.89837</td>\n",
              "      <td>36.29772</td>\n",
              "      <td>2.58776</td>\n",
              "      <td>0.97170</td>\n",
              "      <td>-26.21683</td>\n",
              "      <td>5.05097</td>\n",
              "      <td>-10.34124</td>\n",
              "      <td>3.55005</td>\n",
              "      <td>...</td>\n",
              "      <td>34.57337</td>\n",
              "      <td>-171.70734</td>\n",
              "      <td>-16.96705</td>\n",
              "      <td>-46.67617</td>\n",
              "      <td>-12.51516</td>\n",
              "      <td>82.58061</td>\n",
              "      <td>-72.08993</td>\n",
              "      <td>9.90558</td>\n",
              "      <td>199.62971</td>\n",
              "      <td>18.85382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.97020</td>\n",
              "      <td>42.20998</td>\n",
              "      <td>67.09964</td>\n",
              "      <td>8.46791</td>\n",
              "      <td>-15.85279</td>\n",
              "      <td>-16.81409</td>\n",
              "      <td>-12.48207</td>\n",
              "      <td>-9.37636</td>\n",
              "      <td>12.63699</td>\n",
              "      <td>...</td>\n",
              "      <td>9.92661</td>\n",
              "      <td>-55.95724</td>\n",
              "      <td>64.92712</td>\n",
              "      <td>-17.72522</td>\n",
              "      <td>-1.49237</td>\n",
              "      <td>-7.50035</td>\n",
              "      <td>51.76631</td>\n",
              "      <td>7.88713</td>\n",
              "      <td>55.66926</td>\n",
              "      <td>28.74903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2001</td>\n",
              "      <td>50.54767</td>\n",
              "      <td>0.31568</td>\n",
              "      <td>92.35066</td>\n",
              "      <td>22.38696</td>\n",
              "      <td>-25.51870</td>\n",
              "      <td>-19.04928</td>\n",
              "      <td>20.67345</td>\n",
              "      <td>-5.19943</td>\n",
              "      <td>3.63566</td>\n",
              "      <td>...</td>\n",
              "      <td>6.59753</td>\n",
              "      <td>-50.69577</td>\n",
              "      <td>26.02574</td>\n",
              "      <td>18.94430</td>\n",
              "      <td>-0.33730</td>\n",
              "      <td>6.09352</td>\n",
              "      <td>35.18381</td>\n",
              "      <td>5.00283</td>\n",
              "      <td>-11.02257</td>\n",
              "      <td>0.02263</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 91 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-087d47b1-0163-45f1-9a2f-aeb179822744')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-087d47b1-0163-45f1-9a2f-aeb179822744 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-087d47b1-0163-45f1-9a2f-aeb179822744');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bfe6d5fe-8b44-4b09-b968-85322b1c7a6c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bfe6d5fe-8b44-4b09-b968-85322b1c7a6c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bfe6d5fe-8b44-4b09-b968-85322b1c7a6c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.impute import SimpleImputer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "df = pd.read_csv('/content/Middterm2/midterm-regresi-dataset.csv')\n",
        "display(df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/Middterm2/midterm-regresi-dataset.csv')\n",
        "display(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2bWH1xS1BWam",
        "outputId": "18407d34-53fe-433e-f8b0-be376f898f98"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 515344 entries, 0 to 515343\n",
            "Data columns (total 91 columns):\n",
            " #   Column      Non-Null Count   Dtype  \n",
            "---  ------      --------------   -----  \n",
            " 0   2001        515344 non-null  int64  \n",
            " 1   49.94357    515344 non-null  float64\n",
            " 2   21.47114    515344 non-null  float64\n",
            " 3   73.0775     515344 non-null  float64\n",
            " 4   8.74861     515344 non-null  float64\n",
            " 5   -17.40628   515344 non-null  float64\n",
            " 6   -13.09905   515344 non-null  float64\n",
            " 7   -25.01202   515344 non-null  float64\n",
            " 8   -12.23257   515344 non-null  float64\n",
            " 9   7.83089     515344 non-null  float64\n",
            " 10  -2.46783    515344 non-null  float64\n",
            " 11  3.32136     515344 non-null  float64\n",
            " 12  -2.31521    515344 non-null  float64\n",
            " 13  10.20556    515344 non-null  float64\n",
            " 14  611.10913   515344 non-null  float64\n",
            " 15  951.0896    515344 non-null  float64\n",
            " 16  698.11428   515344 non-null  float64\n",
            " 17  408.98485   515344 non-null  float64\n",
            " 18  383.70912   515344 non-null  float64\n",
            " 19  326.51512   515344 non-null  float64\n",
            " 20  238.11327   515344 non-null  float64\n",
            " 21  251.42414   515344 non-null  float64\n",
            " 22  187.17351   515344 non-null  float64\n",
            " 23  100.42652   515344 non-null  float64\n",
            " 24  179.19498   515344 non-null  float64\n",
            " 25  -8.41558    515344 non-null  float64\n",
            " 26  -317.87038  515344 non-null  float64\n",
            " 27  95.86266    515344 non-null  float64\n",
            " 28  48.10259    515344 non-null  float64\n",
            " 29  -95.66303   515344 non-null  float64\n",
            " 30  -18.06215   515344 non-null  float64\n",
            " 31  1.96984     515344 non-null  float64\n",
            " 32  34.42438    515344 non-null  float64\n",
            " 33  11.7267     515344 non-null  float64\n",
            " 34  1.3679      515344 non-null  float64\n",
            " 35  7.79444     515344 non-null  float64\n",
            " 36  -0.36994    515344 non-null  float64\n",
            " 37  -133.67852  515344 non-null  float64\n",
            " 38  -83.26165   515344 non-null  float64\n",
            " 39  -37.29765   515344 non-null  float64\n",
            " 40  73.04667    515344 non-null  float64\n",
            " 41  -37.36684   515344 non-null  float64\n",
            " 42  -3.13853    515344 non-null  float64\n",
            " 43  -24.21531   515344 non-null  float64\n",
            " 44  -13.23066   515344 non-null  float64\n",
            " 45  15.93809    515344 non-null  float64\n",
            " 46  -18.60478   515344 non-null  float64\n",
            " 47  82.15479    515344 non-null  float64\n",
            " 48  240.5798    515344 non-null  float64\n",
            " 49  -10.29407   515344 non-null  float64\n",
            " 50  31.58431    515344 non-null  float64\n",
            " 51  -25.38187   515344 non-null  float64\n",
            " 52  -3.90772    515344 non-null  float64\n",
            " 53  13.29258    515344 non-null  float64\n",
            " 54  41.5506     515344 non-null  float64\n",
            " 55  -7.26272    515344 non-null  float64\n",
            " 56  -21.00863   515344 non-null  float64\n",
            " 57  105.50848   515344 non-null  float64\n",
            " 58  64.29856    515344 non-null  float64\n",
            " 59  26.08481    515344 non-null  float64\n",
            " 60  -44.5911    515344 non-null  float64\n",
            " 61  -8.30657    515344 non-null  float64\n",
            " 62  7.93706     515344 non-null  float64\n",
            " 63  -10.7366    515344 non-null  float64\n",
            " 64  -95.44766   515344 non-null  float64\n",
            " 65  -82.03307   515344 non-null  float64\n",
            " 66  -35.59194   515344 non-null  float64\n",
            " 67  4.69525     515344 non-null  float64\n",
            " 68  70.95626    515344 non-null  float64\n",
            " 69  28.09139    515344 non-null  float64\n",
            " 70  6.02015     515344 non-null  float64\n",
            " 71  -37.13767   515344 non-null  float64\n",
            " 72  -41.1245    515344 non-null  float64\n",
            " 73  -8.40816    515344 non-null  float64\n",
            " 74  7.19877     515344 non-null  float64\n",
            " 75  -8.60176    515344 non-null  float64\n",
            " 76  -5.90857    515344 non-null  float64\n",
            " 77  -12.32437   515344 non-null  float64\n",
            " 78  14.68734    515344 non-null  float64\n",
            " 79  -54.32125   515344 non-null  float64\n",
            " 80  40.14786    515344 non-null  float64\n",
            " 81  13.0162     515344 non-null  float64\n",
            " 82  -54.40548   515344 non-null  float64\n",
            " 83  58.99367    515344 non-null  float64\n",
            " 84  15.37344    515344 non-null  float64\n",
            " 85  1.11144     515344 non-null  float64\n",
            " 86  -23.08793   515344 non-null  float64\n",
            " 87  68.40795    515344 non-null  float64\n",
            " 88  -1.82223    515344 non-null  float64\n",
            " 89  -27.46348   515344 non-null  float64\n",
            " 90  2.26327     515344 non-null  float64\n",
            "dtypes: float64(90), int64(1)\n",
            "memory usage: 357.8 MB\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "None"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# The first column is the target (y) and the rest are features (X)\n",
        "X = df.iloc[:, 1:]\n",
        "y = df.iloc[:, 0]\n",
        "\n",
        "# Since no imputation has been performed, X_imputed is simply X\n",
        "X_imputed = X.copy()\n",
        "\n",
        "# Apply the user's code\n",
        "valid_target_mask = ~y.isna()\n",
        "X_clean = X_imputed[valid_target_mask]\n",
        "y_clean = y[valid_target_mask]\n",
        "\n",
        "print(f\"Original X shape: {X.shape}\")\n",
        "print(f\"Original y shape: {y.shape}\")\n",
        "print(f\"Cleaned X shape: {X_clean.shape}\")\n",
        "print(f\"Cleaned y shape: {y_clean.shape}\")\n",
        "\n",
        "# You can also verify that valid_target_mask contains all True values\n",
        "print(f\"Percentage of non-NaN target values: {valid_target_mask.sum() / len(valid_target_mask) * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPpwGe9fBnGp",
        "outputId": "d22cee1a-2ab0-4dc1-8d14-4cc328430620"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original X shape: (515344, 90)\n",
            "Original y shape: (515344,)\n",
            "Cleaned X shape: (515344, 90)\n",
            "Cleaned y shape: (515344,)\n",
            "Percentage of non-NaN target values: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f81c6e55",
        "outputId": "f86a67fa-7f58-4a7b-e3eb-5419caa8a565"
      },
      "source": [
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X_clean)\n",
        "\n",
        "print(f\"Shape of X_scaled: {X_scaled.shape}\")"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X_scaled: (515344, 90)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06fc0aee",
        "outputId": "14304580-158c-4e62-eb27-d2965ef98fa2"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_clean, test_size=0.2, random_state=42)\n",
        "\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train.shape}\")\n",
        "print(f\"y_test shape: {y_test.shape}\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (412275, 90)\n",
            "X_test shape: (103069, 90)\n",
            "y_train shape: (412275,)\n",
            "y_test shape: (103069,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "4a458335",
        "outputId": "39c34ebf-386b-45b4-e292-4a06f3de2755"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import LeakyReLU\n",
        "\n",
        "model = Sequential([\n",
        "    Dense(512, input_shape=(X_train.shape[1],)), # Changed input_shape to dynamically match X_train features\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(),\n",
        "    Dropout(0.05),\n",
        "\n",
        "    Dense(256),\n",
        "    BatchNormalization(),\n",
        "    LeakyReLU(),\n",
        "    Dropout(0.05),\n",
        "\n",
        "    Dense(128),\n",
        "    LeakyReLU(),\n",
        "\n",
        "    Dense(64),\n",
        "    LeakyReLU(),\n",
        "\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0005),\n",
        "    loss='huber'\n",
        ")\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │        \u001b[38;5;34m46,592\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m32,896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">46,592</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m222,209\u001b[0m (868.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">222,209</span> (868.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m220,673\u001b[0m (862.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">220,673</span> (862.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "25285074",
        "outputId": "0dd6b436-bfff-4683-d8bd-f9be7426f86d"
      },
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# CALLBACKS\n",
        "es = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=30,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    factor=0.5,\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# FIT MODEL\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=200,\n",
        "    batch_size=32,\n",
        "    validation_split=0.2,\n",
        "    callbacks=[es, lr],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "print(\"Training finished.\")\n",
        "\n",
        "# PLOT LOSS\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(history.history['loss'], label='Training Loss')\n",
        "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "plt.title('Model Loss Over Epochs')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 215.7030 - val_loss: 26.0161 - learning_rate: 5.0000e-04\n",
            "Epoch 2/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 7ms/step - loss: 42.1402 - val_loss: 16.3034 - learning_rate: 5.0000e-04\n",
            "Epoch 3/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 30.8431 - val_loss: 11.8872 - learning_rate: 5.0000e-04\n",
            "Epoch 4/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m92s\u001b[0m 8ms/step - loss: 25.8960 - val_loss: 9.7858 - learning_rate: 5.0000e-04\n",
            "Epoch 5/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 23.5341 - val_loss: 6.5783 - learning_rate: 5.0000e-04\n",
            "Epoch 6/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 22.3373 - val_loss: 7.9877 - learning_rate: 5.0000e-04\n",
            "Epoch 7/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 21.1850 - val_loss: 7.2161 - learning_rate: 5.0000e-04\n",
            "Epoch 8/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 19.9684 - val_loss: 9.0839 - learning_rate: 5.0000e-04\n",
            "Epoch 9/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 18.6636 - val_loss: 7.7229 - learning_rate: 5.0000e-04\n",
            "Epoch 10/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 16.5394 - val_loss: 6.3156 - learning_rate: 5.0000e-04\n",
            "Epoch 11/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 13.3888 - val_loss: 6.1950 - learning_rate: 5.0000e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 9.8839 - val_loss: 6.9471 - learning_rate: 5.0000e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 7.5940 - val_loss: 9.8947 - learning_rate: 5.0000e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 6.8875 - val_loss: 5.6673 - learning_rate: 5.0000e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 6.2863 - val_loss: 5.4202 - learning_rate: 5.0000e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.7638 - val_loss: 5.7454 - learning_rate: 5.0000e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.7038 - val_loss: 5.4147 - learning_rate: 5.0000e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.7037 - val_loss: 6.3949 - learning_rate: 5.0000e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.6825 - val_loss: 5.6556 - learning_rate: 5.0000e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.6412 - val_loss: 5.3858 - learning_rate: 5.0000e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 5.6315 - val_loss: 5.4613 - learning_rate: 5.0000e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.6470 - val_loss: 5.3047 - learning_rate: 5.0000e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.6506 - val_loss: 5.2911 - learning_rate: 5.0000e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.6216 - val_loss: 5.3183 - learning_rate: 5.0000e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.6141 - val_loss: 5.2846 - learning_rate: 5.0000e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 7ms/step - loss: 5.6014 - val_loss: 5.3672 - learning_rate: 5.0000e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.6035 - val_loss: 5.2655 - learning_rate: 5.0000e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.6147 - val_loss: 5.5479 - learning_rate: 5.0000e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.6338 - val_loss: 5.3749 - learning_rate: 5.0000e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.5897 - val_loss: 5.3327 - learning_rate: 5.0000e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.5819 - val_loss: 5.3477 - learning_rate: 5.0000e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 5.5893 - val_loss: 5.2483 - learning_rate: 5.0000e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.5905 - val_loss: 5.2864 - learning_rate: 5.0000e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.5699 - val_loss: 5.2553 - learning_rate: 5.0000e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.5762 - val_loss: 5.2446 - learning_rate: 5.0000e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.5615 - val_loss: 5.4474 - learning_rate: 5.0000e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.5644 - val_loss: 5.4606 - learning_rate: 5.0000e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.5490 - val_loss: 5.7500 - learning_rate: 5.0000e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.6004 - val_loss: 5.2336 - learning_rate: 5.0000e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.5986 - val_loss: 5.3275 - learning_rate: 5.0000e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.5750 - val_loss: 6.2980 - learning_rate: 5.0000e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.5554 - val_loss: 5.3232 - learning_rate: 5.0000e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 5.5769 - val_loss: 5.2305 - learning_rate: 5.0000e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.5727 - val_loss: 5.2496 - learning_rate: 5.0000e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 7ms/step - loss: 5.5302 - val_loss: 5.2904 - learning_rate: 5.0000e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.5359 - val_loss: 5.2465 - learning_rate: 5.0000e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 5.5478 - val_loss: 5.2544 - learning_rate: 5.0000e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.5284 - val_loss: 5.2114 - learning_rate: 5.0000e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.5441 - val_loss: 5.4961 - learning_rate: 5.0000e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.5332 - val_loss: 5.6698 - learning_rate: 5.0000e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.5343 - val_loss: 5.3535 - learning_rate: 5.0000e-04\n",
            "Epoch 52/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 7ms/step - loss: 5.5314 - val_loss: 5.2752 - learning_rate: 5.0000e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.5705 - val_loss: 5.2400 - learning_rate: 5.0000e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.5346 - val_loss: 5.4641 - learning_rate: 5.0000e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.5386 - val_loss: 5.3138 - learning_rate: 5.0000e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.4866 - val_loss: 5.3849 - learning_rate: 5.0000e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.5149 - val_loss: 5.5571 - learning_rate: 5.0000e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m10304/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.5281\n",
            "Epoch 58: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.5281 - val_loss: 5.8040 - learning_rate: 5.0000e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.4079 - val_loss: 5.2354 - learning_rate: 2.5000e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.3936 - val_loss: 5.3171 - learning_rate: 2.5000e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 5.4045 - val_loss: 5.2052 - learning_rate: 2.5000e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.3927 - val_loss: 5.1797 - learning_rate: 2.5000e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.4010 - val_loss: 5.4389 - learning_rate: 2.5000e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.3927 - val_loss: 5.1655 - learning_rate: 2.5000e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.4219 - val_loss: 5.1928 - learning_rate: 2.5000e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.4060 - val_loss: 5.1957 - learning_rate: 2.5000e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.3891 - val_loss: 5.1669 - learning_rate: 2.5000e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.3897 - val_loss: 5.1686 - learning_rate: 2.5000e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.3974 - val_loss: 5.1742 - learning_rate: 2.5000e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.4109 - val_loss: 5.2119 - learning_rate: 2.5000e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.4034 - val_loss: 5.1989 - learning_rate: 2.5000e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.4063 - val_loss: 5.2463 - learning_rate: 2.5000e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.3764 - val_loss: 5.1959 - learning_rate: 2.5000e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m10299/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 5.4010\n",
            "Epoch 74: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.4010 - val_loss: 5.2850 - learning_rate: 2.5000e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.3355 - val_loss: 5.1672 - learning_rate: 1.2500e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.3351 - val_loss: 5.2536 - learning_rate: 1.2500e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.3188 - val_loss: 5.2327 - learning_rate: 1.2500e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.3469 - val_loss: 5.2044 - learning_rate: 1.2500e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.3298 - val_loss: 5.1560 - learning_rate: 1.2500e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.3131 - val_loss: 5.1800 - learning_rate: 1.2500e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.3439 - val_loss: 5.1469 - learning_rate: 1.2500e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 5.3234 - val_loss: 5.1828 - learning_rate: 1.2500e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.3315 - val_loss: 5.1719 - learning_rate: 1.2500e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.3183 - val_loss: 5.1613 - learning_rate: 1.2500e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.3236 - val_loss: 5.1545 - learning_rate: 1.2500e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.3247 - val_loss: 5.1494 - learning_rate: 1.2500e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.3330 - val_loss: 5.1624 - learning_rate: 1.2500e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.3233 - val_loss: 5.1709 - learning_rate: 1.2500e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.3344 - val_loss: 5.1545 - learning_rate: 1.2500e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.3082 - val_loss: 5.1581 - learning_rate: 1.2500e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m10305/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.3168\n",
            "Epoch 91: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.3168 - val_loss: 5.3263 - learning_rate: 1.2500e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2838 - val_loss: 5.1443 - learning_rate: 6.2500e-05\n",
            "Epoch 93/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.2828 - val_loss: 5.1824 - learning_rate: 6.2500e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2885 - val_loss: 5.1591 - learning_rate: 6.2500e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.2815 - val_loss: 5.1422 - learning_rate: 6.2500e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2889 - val_loss: 5.1401 - learning_rate: 6.2500e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2862 - val_loss: 5.1369 - learning_rate: 6.2500e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.3014 - val_loss: 5.1381 - learning_rate: 6.2500e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2890 - val_loss: 5.1419 - learning_rate: 6.2500e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2878 - val_loss: 5.1535 - learning_rate: 6.2500e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2780 - val_loss: 5.1422 - learning_rate: 6.2500e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2981 - val_loss: 5.1584 - learning_rate: 6.2500e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2777 - val_loss: 5.2396 - learning_rate: 6.2500e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2744 - val_loss: 5.1455 - learning_rate: 6.2500e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.2755 - val_loss: 5.1524 - learning_rate: 6.2500e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2932 - val_loss: 5.1359 - learning_rate: 6.2500e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2689 - val_loss: 5.1615 - learning_rate: 6.2500e-05\n",
            "Epoch 108/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.2941 - val_loss: 5.1361 - learning_rate: 6.2500e-05\n",
            "Epoch 109/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2797 - val_loss: 5.1537 - learning_rate: 6.2500e-05\n",
            "Epoch 110/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.2837 - val_loss: 5.1447 - learning_rate: 6.2500e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.2897 - val_loss: 5.2033 - learning_rate: 6.2500e-05\n",
            "Epoch 112/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2877 - val_loss: 5.1372 - learning_rate: 6.2500e-05\n",
            "Epoch 113/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2833 - val_loss: 5.1454 - learning_rate: 6.2500e-05\n",
            "Epoch 114/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 7ms/step - loss: 5.3048 - val_loss: 5.2141 - learning_rate: 6.2500e-05\n",
            "Epoch 115/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 5.2860 - val_loss: 5.1972 - learning_rate: 6.2500e-05\n",
            "Epoch 116/200\n",
            "\u001b[1m10302/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2847\n",
            "Epoch 116: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2847 - val_loss: 5.1401 - learning_rate: 6.2500e-05\n",
            "Epoch 117/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 5.2687 - val_loss: 5.1384 - learning_rate: 3.1250e-05\n",
            "Epoch 118/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 5.2601 - val_loss: 5.1332 - learning_rate: 3.1250e-05\n",
            "Epoch 119/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2542 - val_loss: 5.1383 - learning_rate: 3.1250e-05\n",
            "Epoch 120/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 5.2587 - val_loss: 5.1931 - learning_rate: 3.1250e-05\n",
            "Epoch 121/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2475 - val_loss: 5.1366 - learning_rate: 3.1250e-05\n",
            "Epoch 122/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 5.2353 - val_loss: 5.1437 - learning_rate: 3.1250e-05\n",
            "Epoch 123/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2641 - val_loss: 5.1504 - learning_rate: 3.1250e-05\n",
            "Epoch 124/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 5.2607 - val_loss: 5.1652 - learning_rate: 3.1250e-05\n",
            "Epoch 125/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 7ms/step - loss: 5.2467 - val_loss: 5.1395 - learning_rate: 3.1250e-05\n",
            "Epoch 126/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2481 - val_loss: 5.1432 - learning_rate: 3.1250e-05\n",
            "Epoch 127/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 5.2438 - val_loss: 5.1316 - learning_rate: 3.1250e-05\n",
            "Epoch 128/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 5.2385 - val_loss: 5.1499 - learning_rate: 3.1250e-05\n",
            "Epoch 129/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 7ms/step - loss: 5.2384 - val_loss: 5.1370 - learning_rate: 3.1250e-05\n",
            "Epoch 130/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2415 - val_loss: 5.1916 - learning_rate: 3.1250e-05\n",
            "Epoch 131/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 7ms/step - loss: 5.2304 - val_loss: 5.1658 - learning_rate: 3.1250e-05\n",
            "Epoch 132/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2319 - val_loss: 5.1387 - learning_rate: 3.1250e-05\n",
            "Epoch 133/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2630 - val_loss: 5.1322 - learning_rate: 3.1250e-05\n",
            "Epoch 134/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2520 - val_loss: 5.1318 - learning_rate: 3.1250e-05\n",
            "Epoch 135/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2533 - val_loss: 5.1569 - learning_rate: 3.1250e-05\n",
            "Epoch 136/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 5.2599 - val_loss: 5.1733 - learning_rate: 3.1250e-05\n",
            "Epoch 137/200\n",
            "\u001b[1m10300/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2453\n",
            "Epoch 137: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2453 - val_loss: 5.1370 - learning_rate: 3.1250e-05\n",
            "Epoch 138/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2439 - val_loss: 5.1362 - learning_rate: 1.5625e-05\n",
            "Epoch 139/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2364 - val_loss: 5.1316 - learning_rate: 1.5625e-05\n",
            "Epoch 140/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2261 - val_loss: 5.1319 - learning_rate: 1.5625e-05\n",
            "Epoch 141/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2476 - val_loss: 5.1416 - learning_rate: 1.5625e-05\n",
            "Epoch 142/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2564 - val_loss: 5.1305 - learning_rate: 1.5625e-05\n",
            "Epoch 143/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2382 - val_loss: 5.1302 - learning_rate: 1.5625e-05\n",
            "Epoch 144/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2376 - val_loss: 5.1353 - learning_rate: 1.5625e-05\n",
            "Epoch 145/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2495 - val_loss: 5.1268 - learning_rate: 1.5625e-05\n",
            "Epoch 146/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2363 - val_loss: 5.1269 - learning_rate: 1.5625e-05\n",
            "Epoch 147/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2194 - val_loss: 5.1315 - learning_rate: 1.5625e-05\n",
            "Epoch 148/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2496 - val_loss: 5.1300 - learning_rate: 1.5625e-05\n",
            "Epoch 149/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m85s\u001b[0m 8ms/step - loss: 5.2363 - val_loss: 5.1446 - learning_rate: 1.5625e-05\n",
            "Epoch 150/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 5.2288 - val_loss: 5.1483 - learning_rate: 1.5625e-05\n",
            "Epoch 151/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 5.2736 - val_loss: 5.1303 - learning_rate: 1.5625e-05\n",
            "Epoch 152/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2514 - val_loss: 5.1353 - learning_rate: 1.5625e-05\n",
            "Epoch 153/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2345 - val_loss: 5.1425 - learning_rate: 1.5625e-05\n",
            "Epoch 154/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2342 - val_loss: 5.1481 - learning_rate: 1.5625e-05\n",
            "Epoch 155/200\n",
            "\u001b[1m10303/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2361\n",
            "Epoch 155: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2361 - val_loss: 5.1277 - learning_rate: 1.5625e-05\n",
            "Epoch 156/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2330 - val_loss: 5.1292 - learning_rate: 7.8125e-06\n",
            "Epoch 157/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2251 - val_loss: 5.1259 - learning_rate: 7.8125e-06\n",
            "Epoch 158/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2148 - val_loss: 5.1305 - learning_rate: 7.8125e-06\n",
            "Epoch 159/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2401 - val_loss: 5.1599 - learning_rate: 7.8125e-06\n",
            "Epoch 160/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2278 - val_loss: 5.1242 - learning_rate: 7.8125e-06\n",
            "Epoch 161/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2354 - val_loss: 5.1238 - learning_rate: 7.8125e-06\n",
            "Epoch 162/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 5.2558 - val_loss: 5.1237 - learning_rate: 7.8125e-06\n",
            "Epoch 163/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2314 - val_loss: 5.1291 - learning_rate: 7.8125e-06\n",
            "Epoch 164/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.2259 - val_loss: 5.1243 - learning_rate: 7.8125e-06\n",
            "Epoch 165/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2120 - val_loss: 5.1313 - learning_rate: 7.8125e-06\n",
            "Epoch 166/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.2460 - val_loss: 5.1292 - learning_rate: 7.8125e-06\n",
            "Epoch 167/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2190 - val_loss: 5.1366 - learning_rate: 7.8125e-06\n",
            "Epoch 168/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 7ms/step - loss: 5.2470 - val_loss: 5.1238 - learning_rate: 7.8125e-06\n",
            "Epoch 169/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2447 - val_loss: 5.1251 - learning_rate: 7.8125e-06\n",
            "Epoch 170/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 7ms/step - loss: 5.2340 - val_loss: 5.1376 - learning_rate: 7.8125e-06\n",
            "Epoch 171/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2142 - val_loss: 5.1241 - learning_rate: 7.8125e-06\n",
            "Epoch 172/200\n",
            "\u001b[1m10303/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2415\n",
            "Epoch 172: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 7ms/step - loss: 5.2415 - val_loss: 5.1481 - learning_rate: 7.8125e-06\n",
            "Epoch 173/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2359 - val_loss: 5.1324 - learning_rate: 3.9063e-06\n",
            "Epoch 174/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2175 - val_loss: 5.1285 - learning_rate: 3.9063e-06\n",
            "Epoch 175/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2262 - val_loss: 5.1238 - learning_rate: 3.9063e-06\n",
            "Epoch 176/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2452 - val_loss: 5.1237 - learning_rate: 3.9063e-06\n",
            "Epoch 177/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 7ms/step - loss: 5.2212 - val_loss: 5.1237 - learning_rate: 3.9063e-06\n",
            "Epoch 178/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2392 - val_loss: 5.1275 - learning_rate: 3.9063e-06\n",
            "Epoch 179/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2142 - val_loss: 5.1272 - learning_rate: 3.9063e-06\n",
            "Epoch 180/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 5.2299 - val_loss: 5.1217 - learning_rate: 3.9063e-06\n",
            "Epoch 181/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2373 - val_loss: 5.1267 - learning_rate: 3.9063e-06\n",
            "Epoch 182/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2488 - val_loss: 5.1246 - learning_rate: 3.9063e-06\n",
            "Epoch 183/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2317 - val_loss: 5.1289 - learning_rate: 3.9063e-06\n",
            "Epoch 184/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 8ms/step - loss: 5.2451 - val_loss: 5.1254 - learning_rate: 3.9063e-06\n",
            "Epoch 185/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2329 - val_loss: 5.1256 - learning_rate: 3.9063e-06\n",
            "Epoch 186/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2303 - val_loss: 5.1229 - learning_rate: 3.9063e-06\n",
            "Epoch 187/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2247 - val_loss: 5.1267 - learning_rate: 3.9063e-06\n",
            "Epoch 188/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2640 - val_loss: 5.1232 - learning_rate: 3.9063e-06\n",
            "Epoch 189/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m79s\u001b[0m 8ms/step - loss: 5.2510 - val_loss: 5.1275 - learning_rate: 3.9063e-06\n",
            "Epoch 190/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 8ms/step - loss: 5.2148 - val_loss: 5.1208 - learning_rate: 3.9063e-06\n",
            "Epoch 191/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 8ms/step - loss: 5.2332 - val_loss: 5.1225 - learning_rate: 3.9063e-06\n",
            "Epoch 192/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2377 - val_loss: 5.1241 - learning_rate: 3.9063e-06\n",
            "Epoch 193/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2213 - val_loss: 5.1279 - learning_rate: 3.9063e-06\n",
            "Epoch 194/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2568 - val_loss: 5.1231 - learning_rate: 3.9063e-06\n",
            "Epoch 195/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2354 - val_loss: 5.1224 - learning_rate: 3.9063e-06\n",
            "Epoch 196/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2345 - val_loss: 5.1255 - learning_rate: 3.9063e-06\n",
            "Epoch 197/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2206 - val_loss: 5.1247 - learning_rate: 3.9063e-06\n",
            "Epoch 198/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 7ms/step - loss: 5.2379 - val_loss: 5.1295 - learning_rate: 3.9063e-06\n",
            "Epoch 199/200\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 7ms/step - loss: 5.2292 - val_loss: 5.1264 - learning_rate: 3.9063e-06\n",
            "Epoch 200/200\n",
            "\u001b[1m10303/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 5.2127\n",
            "Epoch 200: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
            "\u001b[1m10307/10307\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 7ms/step - loss: 5.2127 - val_loss: 5.1331 - learning_rate: 3.9063e-06\n",
            "Training finished.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0kAAAIjCAYAAADWYVDIAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAbkhJREFUeJzt3Xd8VFX+//H3nZLeqEmAUAUpUhQEsaAuSBVBURFRcEVZVyzYlnVdXGTXvqt+7bI/BV3FLui6Kk3AhoAgTRGlg0CQkgQSkkwy5/fHZIaEBAghM/cSXs/HYx6ZuffOvZ975hLmnXPvuZYxxggAAAAAIEly2V0AAAAAADgJIQkAAAAASiEkAQAAAEAphCQAAAAAKIWQBAAAAAClEJIAAAAAoBRCEgAAAACUQkgCAAAAgFIISQAAAABQCiEJAGooy7I0YcKEY37fxo0bZVmWpkyZUu01oWYIHiP//Oc/7S4FAMKCkAQAYTRlyhRZliXLsvTVV1+Vm2+MUUZGhizL0sUXX2xDhVU3b948WZal9957z+5SKuWHH37QNddco4YNGyo6OloNGjTQ8OHD9cMPP9hdWjnBEHK4xyOPPGJ3iQBQo3nsLgAATgYxMTGaOnWqzj333DLT58+fr61btyo6Otqmyk4OH3zwgYYNG6batWtr1KhRatasmTZu3KiXX35Z7733nt566y1deumldpdZzrBhw9S/f/9y008//XQbqgGAkwchCQAioH///nr33Xf19NNPy+M5+Kt36tSp6ty5s3bt2mVjdTXbunXrdO2116p58+b64osvVK9evdC822+/Xeedd56uvfZarVixQs2bN49YXbm5uYqPjz/iMmeccYauueaaCFUEAAjidDsAiIBhw4Zp9+7dmjVrVmhaYWGh3nvvPV199dUVvic3N1d33XWXMjIyFB0drVNPPVX//Oc/ZYwps1xBQYHuuOMO1atXT4mJibrkkku0devWCtf566+/6vrrr1dqaqqio6PVrl07vfLKK9W3oxVYv369rrjiCtWuXVtxcXE666yz9L///a/ccs8884zatWunuLg41apVS126dNHUqVND8/ft26exY8eqadOmio6OVv369XXRRRdp6dKlR9z+448/rry8PE2aNKlMQJKkunXr6qWXXlJubq4ee+wxSdJ7770ny7I0f/78cut66aWXZFmWVq1aFZr2008/6fLLL1ft2rUVExOjLl266KOPPirzvuBpl/Pnz9fNN9+s+vXrq1GjRkdvvEpo2rSpLr74Ys2cOVOdOnVSTEyM2rZtqw8++KDcspX9LPLz8zVhwgS1atVKMTExSk9P12WXXaZ169aVW3bSpElq0aKFoqOjdeaZZ2rx4sVl5u/YsUO///3v1ahRI0VHRys9PV2DBg3Sxo0bq2X/ASAc6EkCgAho2rSpunfvrjfffFP9+vWTJH366afKzs7WVVddpaeffrrM8sYYXXLJJZo7d65GjRqlTp06acaMGbrnnnv066+/6sknnwwte8MNN+j111/X1VdfrbPPPluff/65BgwYUK6GzMxMnXXWWbIsS7fccovq1aunTz/9VKNGjVJOTo7Gjh1b7fudmZmps88+W3l5ebrttttUp04dvfrqq7rkkkv03nvvhU5x+/e//63bbrtNl19+uW6//Xbl5+drxYoVWrhwYShE3nTTTXrvvfd0yy23qG3bttq9e7e++uorrV69WmecccZha/jvf/+rpk2b6rzzzqtwfo8ePdS0adNQWBgwYIASEhL0zjvv6Pzzzy+z7Ntvv6127drptNNOkxS4zumcc85Rw4YN9ec//1nx8fF65513NHjwYL3//vvlTuG7+eabVa9ePd1///3Kzc09avvl5eVV2MuYkpJSpkfyl19+0dChQ3XTTTdp5MiRmjx5sq644gp99tlnuuiiiyRV/rMoLi7WxRdfrDlz5uiqq67S7bffrn379mnWrFlatWqVWrRoEdru1KlTtW/fPv3hD3+QZVl67LHHdNlll2n9+vXyer2SpCFDhuiHH37QrbfeqqZNm2rnzp2aNWuWNm/erKZNmx61DQDAFgYAEDaTJ082kszixYvNs88+axITE01eXp4xxpgrrrjCXHjhhcYYY5o0aWIGDBgQet/06dONJPOPf/yjzPouv/xyY1mWWbt2rTHGmGXLlhlJ5uabby6z3NVXX20kmb/97W+haaNGjTLp6elm165dZZa96qqrTHJycqiuDRs2GElm8uTJR9y3uXPnGknm3XffPewyY8eONZLMl19+GZq2b98+06xZM9O0aVNTXFxsjDFm0KBBpl27dkfcXnJyshkzZswRlzlUVlaWkWQGDRp0xOUuueQSI8nk5OQYY4wZNmyYqV+/vikqKgots337duNyuczEiRND03r27Gnat29v8vPzQ9P8fr85++yzTcuWLUPTgsfBueeeW2adhxP8DA73WLBgQWjZJk2aGEnm/fffD03Lzs426enp5vTTTw9Nq+xn8corrxhJ5oknnihXl9/vL1NfnTp1zJ49e0LzP/zwQyPJ/Pe//zXGGLN3714jyTz++ONH3WcAcBJOtwOACLnyyit14MABffzxx9q3b58+/vjjw55q98knn8jtduu2224rM/2uu+6SMUaffvppaDlJ5ZY7tFfIGKP3339fAwcOlDFGu3btCj369Omj7Ozso562VhWffPKJunbtWmbAioSEBI0ePVobN27Ujz/+KCnQM7J169Zyp2qVlpKSooULF2rbtm2V3v6+ffskSYmJiUdcLjg/JydHkjR06FDt3LlT8+bNCy3z3nvvye/3a+jQoZKkPXv26PPPP9eVV16pffv2hdpz9+7d6tOnj3755Rf9+uuvZbZz4403yu12V7r+0aNHa9asWeUebdu2LbNcgwYNyvRaJSUlacSIEfr++++1Y8cOSZX/LN5//33VrVtXt956a7l6LMsq83ro0KGqVatW6HWwt279+vWSpNjYWEVFRWnevHnau3dvpfcbAOzG6XYAECH16tVTr169NHXqVOXl5am4uFiXX355hctu2rRJDRo0KPflvk2bNqH5wZ8ul6vMKVCSdOqpp5Z5/dtvvykrK0uTJk3SpEmTKtzmzp07q7RfR7Jp0yZ169at3PTS+3Haaadp3Lhxmj17trp27apTTjlFvXv31tVXX61zzjkn9J7HHntMI0eOVEZGhjp37qz+/ftrxIgRRxxsIdh+wbB0OIeGqb59+yo5OVlvv/22evbsKSlwql2nTp3UqlUrSdLatWtljNH48eM1fvz4Cte7c+dONWzYMPS6WbNmR6zjUC1btlSvXr2Outwpp5xSLsAE69y4caPS0tIq/VmsW7dOp556apnT+Q6ncePGZV4HA1MwEEVHR+vRRx/VXXfdpdTUVJ111lm6+OKLNWLECKWlpR11/QBgF0ISAETQ1VdfrRtvvFE7duxQv379lJKSEpHt+v1+SdI111yjkSNHVrhMhw4dIlJLRdq0aaM1a9bo448/1meffab3339fzz//vO6//3498MADkgI9ceedd56mTZummTNn6vHHH9ejjz6qDz74IHSd16GSk5OVnp6uFStWHHH7K1asUMOGDZWUlCQp8OV+8ODBmjZtmp5//nllZmbq66+/1kMPPRR6T7BN7777bvXp06fC9Z5yyillXsfGxlauQU4Qh+sVM6UGFxk7dqwGDhyo6dOna8aMGRo/frwefvhhff755wxlDsCxON0OACLo0ksvlcvl0rfffnvYU+0kqUmTJtq2bVu5HpCffvopND/40+/3lxt1bM2aNWVeB0e+Ky4uVq9evSp81K9fvzp2sdx+HFpLRfshSfHx8Ro6dKgmT56szZs3a8CAAXrwwQeVn58fWiY9PV0333yzpk+frg0bNqhOnTp68MEHj1jDxRdfrA0bNlR4M19J+vLLL7Vx48ZyN/MdOnSodu3apTlz5ujdd9+VMSZ0qp2kUA+W1+s9bJse7TS/6hLs1Srt559/lqTQ4AiV/SxatGihNWvWyOfzVVt9LVq00F133aWZM2dq1apVKiws1L/+9a9qWz8AVDdCEgBEUEJCgl544QVNmDBBAwcOPOxy/fv3V3FxsZ599tky05988klZlhXqOQn+PHR0vKeeeqrMa7fbrSFDhuj9998vM3x10G+//VaV3Tmq/v37a9GiRVqwYEFoWm5uriZNmqSmTZuGrq3ZvXt3mfdFRUWpbdu2MsbI5/OpuLhY2dnZZZapX7++GjRooIKCgiPWcM899yg2NlZ/+MMfym1nz549uummmxQXF6d77rmnzLxevXqpdu3aevvtt/X222+ra9euZU6Xq1+/vi644AK99NJL2r59e7nthqtNK7Jt2zZNmzYt9DonJ0evvfaaOnXqFDqtrbKfxZAhQ7Rr165yx56kckHsaPLy8sqEXCkQmBITE4/6uQGAnTjdDgAi7HCnu5U2cOBAXXjhhbrvvvu0ceNGdezYUTNnztSHH36osWPHhq5B6tSpk4YNG6bnn39e2dnZOvvsszVnzhytXbu23DofeeQRzZ07V926ddONN96otm3bas+ePVq6dKlmz56tPXv2VGl/3n///VBvxKH7+ec//zk07Pltt92m2rVr69VXX9WGDRv0/vvvy+UK/K2ud+/eSktL0znnnKPU1FStXr1azz77rAYMGKDExERlZWWpUaNGuvzyy9WxY0clJCRo9uzZWrx48VF7JFq2bKlXX31Vw4cPV/v27TVq1Cg1a9ZMGzdu1Msvv6xdu3bpzTffLHddl9fr1WWXXaa33npLubm5+uc//1lu3c8995zOPfdctW/fXjfeeKOaN2+uzMxMLViwQFu3btXy5cur1KZBS5cu1euvv15ueosWLdS9e/fQ61atWmnUqFFavHixUlNT9corrygzM1OTJ08OLVPZz2LEiBF67bXXdOedd2rRokU677zzlJubq9mzZ+vmm2/WoEGDKl3/zz//rJ49e+rKK69U27Zt5fF4NG3aNGVmZuqqq646jpYBgDCzbVw9ADgJlB4C/EgOHQLcmMDwzHfccYdp0KCB8Xq9pmXLlubxxx8PDcMcdODAAXPbbbeZOnXqmPj4eDNw4ECzZcuWckOAG2NMZmamGTNmjMnIyDBer9ekpaWZnj17mkmTJoWWOdYhwA/3CA41vW7dOnP55ZeblJQUExMTY7p27Wo+/vjjMut66aWXTI8ePUydOnVMdHS0adGihbnnnntMdna2McaYgoICc88995iOHTuaxMREEx8fbzp27Gief/75I9ZY2ooVK8ywYcNMenp6aN+HDRtmVq5cedj3zJo1y0gylmWZLVu2VLjMunXrzIgRI0xaWprxer2mYcOG5uKLLzbvvfdeaJnKHgdBRxsCfOTIkaFlg8fOjBkzTIcOHUx0dLRp3bp1hUOzV+azMMaYvLw8c99995lmzZqF2uryyy8369atK1NfRUN7lz7udu3aZcaMGWNat25t4uPjTXJysunWrZt55513KtUOAGAXy5hj7DsHAACO0bRpU5122mn6+OOP7S4FAGoMrkkCAAAAgFIISQAAAABQCiEJAAAAAErhmiQAAAAAKIWeJAAAAAAohZAEAAAAAKXU+JvJ+v1+bdu2TYmJibIsy+5yAAAAANjEGKN9+/apQYMGoZtoV6TGh6Rt27YpIyPD7jIAAAAAOMSWLVvUqFGjw86v8SEpMTFRUqAhkpKSbK3F5/Np5syZ6t27t7xer6211FS0cXjRvuFHG4cX7Rt+tHF40b7hRxuHl93tm5OTo4yMjFBGOJwaH5KCp9glJSU5IiTFxcUpKSmJf3RhQhuHF+0bfrRxeNG+4UcbhxftG360cXg5pX2PdhkOAzcAAAAAQCmEJAAAAAAohZAEAAAAAKXU+GuSAAAA4CzGGBUVFam4uNjuUsrx+XzyeDzKz893ZH0nunC3r9vtlsfjOe5b/xCSAAAAEDGFhYXavn278vLy7C6lQsYYpaWlacuWLdxjMwwi0b5xcXFKT09XVFRUlddBSAIAAEBE+P1+bdiwQW63Ww0aNFBUVJTjgojf79f+/fuVkJBwxJuNomrC2b7GGBUWFuq3337Thg0b1LJlyypvg5AEAACAiCgsLJTf71dGRobi4uLsLqdCfr9fhYWFiomJISSFQbjbNzY2Vl6vV5s2bQptpyr45AEAABBRhA+EU3UcXxyhAAAAAFAKIQkAAAAASiEkAQAAADZo2rSpnnrqqUovP2/ePFmWpaysrLDVhABCEgAAAHAElmUd8TFhwoQqrXfx4sUaPXp0pZc/++yztX37diUnJ1dpe5VFGGN0OwAAAOCItm/fHnr+9ttv6/7779eaNWtC0xISEkLPjTEqLi6Wx3P0r9n16tU7pjqioqKUlpZ2TO9B1dCTBAAAANsYY5RXWGTLwxhTqRrT0tJCj+TkZFmWFXr9008/KTExUZ9++qk6d+6s6OhoffXVV1q3bp0GDRqk1NRUJSQk6Mwzz9Ts2bPLrPfQ0+0sy9L/+3//T5deeqni4uLUsmVLffTRR6H5h/bwTJkyRSkpKZoxY4batGmjhIQE9e3bt0yoKyoq0m233aaUlBTVqVNH48aN08iRIzV48OAqf2Z79+7ViBEjVKtWLcXFxalfv3765ZdfQvM3bdqkgQMHqlatWoqPj1e7du30ySefhN574403KjU1VbGxsWrZsqUmT55c5VrChZ4kAAAA2OaAr1ht759hy7Z/nNhHcVHV83X4z3/+s/75z3+qefPmqlWrlrZs2aL+/fvrwQcfVHR0tF577TUNHDhQa9asUePGjQ+7ngceeECPPfaYHn/8cT3zzDMaPny4Nm3apNq1a1e4fF5env75z3/qP//5j1wul6655hrdfffdeuONNyRJjz76qN544w1NnjxZbdq00f/93/9p+vTpuvDCC6u8r9ddd51++eUXffTRR0pKStK4cePUv39//fjjj/J6vRozZowKCwv1xRdfKD4+Xj/++GOoty3YC/e///1P9evX19q1a3XgwIEq1xIuhCQAAADgOE2cOFEXXXRR6HXt2rXVsWPH0Ou///3vmjZtmj766CPdcssth13Pddddp2HDhkmSHnroIT399NNatGiR+vbtW+HyPp9PL774olq0aCFJuuWWWzRx4sTQ/GeeeUb33nuvLr30UknSs88+G+rVqYpgOPr666919tlnS5LeeOMNZWRkaPr06briiiu0efNmDRkyRO3bt5ckNW/ePPT+zZs3q0OHDurSpYtcLpeaNm1a5VrCiZAUQfN+/k3Ldls6L79Itb1eu8sBAACwXazXrR8n9rFt29WlS5cuZV7v379fEyZM0P/+9z9t375dRUVFOnDggDZv3nzE9XTo0CH0PD4+XklJSdq5c+dhl4+LiwsFJElKT08PLZ+dna3MzEx17do1NN/tdqtz587y+/3HtH9Bq1evlsfjUbdu3ULT6tSpo1NPPVWrV6+WJN1222364x//qJkzZ6pXr14aMmRIaL9uuukmXXHFFVq1apV69+6twYMHh8KWk3BNUgT96f1VmvyzWzuy8+0uBQAAwBEsy1JclMeWh2VZ1bYf8fHxZV7ffffdmjZtmh566CF9+eWXWrZsmdq3b6/CwsIjrsd7yB/SLcs6YqCpaPnKXmsVLjfccIPWr1+va6+9VitXrlSXLl30zDPPSJL69eunFStW6Pbbb9e2bdvUs2dP3X333bbWWxFCUgR5XIF/iMU2H7gAAAAIr6+//lrXXXedLr30UrVv315paWnauHFjRGtITk5WamqqFi9eHJpWXFyspUuXVnmdbdq0UVFRkRYuXBiatnv3bq1Zs0Zt27YNTcvIyNBNN92kDz74QHfddZf+/e9/h+bVrVtXI0eO1Ouvv66nnnpKkyZNqnI94cLpdhHkCoYkPyEJAACgJmvZsqU++OADDRw4UJZlafz48VU+xe143HrrrXr44Yd1yimnqHXr1nrmmWe0d+/eSvWirVy5UomJiaHXlmWpY8eOGjRokG688Ua99NJLSkxM1J///Gc1bNhQgwYNkiSNHTtW/fr1U6tWrbR3717NnTtXbdq0kST97W9/U5s2bdSlSxf5fD59/PHHoXlOQkiKIA8hCQAA4KTwxBNP6Prrr9fZZ5+tunXraty4ccrJyYl4HePGjdOOHTs0YsQIud1ujR49Wn369JHbffTrsXr06FHmtdvtVlFRkSZPnqzbb79dF198sQoLC9WjRw998sknoVP/iouLNWbMGG3dulVJSUnq27evnnzySUmBez1NnDhRmzdvVmxsrM477zy99dZb1b/jx4mQFEEui5AEAABwIrvuuut03XXXhV5fcMEFFV4D1LRpU33++edlpo0ZM6bM60NPv6toPcF7IlW0rUNrkaTBgweXWcbj8eiZZ54JXRPk9/vVpk0bXXnllRXu35H2KahWrVp67bXXDjs/uK2K3Hfffbr11luVlJQkl8u5V/4QkiKIa5IAAAAQSZs2bdLMmTN1/vnnq6CgQM8++6w2bNigq6++2u7SHM258a0G4pokAAAARJLL5dKUKVN05pln6pxzztHKlSs1e/ZsR14H5CT0JEUQ1yQBAAAgkjIyMvT111/bXcYJh56kCOKaJAAAAMD5CEkR5HFzTRIAAADgdISkCAr1JBUTkgAAAACnIiRFUPCapCJOtwMAAAAci5AUQcHR7fycbgcAAAA4FiEpguhJAgAAAJyPkBRB7mBPEiEJAADgpHPBBRdo7NixoddNmzbVU089dcT3WJal6dOnH/e2q2s9JwtCUgS5LXqSAAAATjQDBw5U3759K5z35ZdfyrIsrVix4pjXu3jxYo0ePfp4yytjwoQJ6tSpU7np27dvV79+/ap1W4eaMmWKUlJSwrqNSCEkRZCba5IAAABOOKNGjdKsWbO0devWcvMmT56sLl26qEOHDse83nr16ikuLq46SjyqtLQ0RUdHR2RbNQEhKYLcXJMEAABQljFSYa49j0r+4friiy9WvXr1NGXKlDLT9+/fr3fffVejRo3S7t27NWzYMDVs2FBxcXFq37693nzzzSOu99DT7X755Rf16NFDMTExatu2rWbNmlXuPePGjVOrVq0UFxen5s2ba/z48fL5fJICPTkPPPCAli9fLsuyZFlWqOZDT7dbuXKlfve73yk2NlZ16tTR6NGjtX///tD86667ToMHD9Y///lPpaenq06dOhozZkxoW1WxefNmDR48WI0aNVJKSoquvPJKZWZmhuYvX75cF154oRITE5WUlKTOnTvru+++kyRt2rRJAwcOVK1atRQfH6927drpk08+qXItR+MJ25pRDtckAQAAHMKXJz3UwJ5t/2WbFBV/1MU8Ho9GjBihKVOm6L777pNVcgnFu+++q+LiYg0bNkz79+9X586dNW7cOCUlJel///ufrr32WrVo0UJdu3Y96jb8fr8uu+wypaamauHChcrOzi5z/VJQYmKipkyZogYNGmjlypW68cYblZiYqD/96U8aOnSoVq1apc8++0yzZ8+WJCUnJ5dbR25urvr06aPu3btr8eLF2rlzp2644QbdcsstZYLg3LlzlZ6errlz52rt2rUaOnSoOnXqpBtvvPGo+1PR/g0aNEgJCQn6+OOPFR0drVtvvVVDhw7VvHnzJEnDhw/X6aefrhdeeEFut1vLli2T1+uVJI0ZM0aFhYX64osvFB8frx9//FEJCQnHXEdlEZIiiGuSAAAATkzXX3+9Hn/8cc2fP18XXHCBpMCpdkOGDFFycrKSk5N19913h5a/9dZbNWPGDL3zzjuVCkmzZ8/WTz/9pBkzZqhBg0BofOihh8pdR/TXv/419Lxp06a6++679dZbb+lPf/qTYmNjlZCQII/Ho7S0tMNua+rUqcrPz9drr72m+PhASHz22Wc1cOBAPfroo0pNTZUk1apVS88++6zcbrdat26tAQMGaM6cOVUKSXPmzNHKlSu1bt06JScnKykpSa+99pratWunxYsX68wzz9TmzZt1zz33qHXr1pKkli1bht6/efNmDRkyRO3bt5ckNW/e/JhrOBaEpAg6eE2SzYUAAAA4hTcu0KNj17YrqXXr1jr77LP1yiuv6IILLtDatWv15ZdfauLEiZKk4uJiPfTQQ3rnnXf066+/qrCwUAUFBZW+5mj16tXKyMgIBSRJ6t69e7nl3n77bT399NNat26d9u/fr6KiIiUlJVV6P4Lb6tixYyggSdI555wjv9+vNWvWhEJSu3bt5Ha7Q8ukp6dr5cqVx7St0tvMyMhQRkaGcnJyJElt27ZVSkqKVq9erTPPPFN33nmnbrjhBv3nP/9Rr169dMUVV6hFixaSpNtuu01//OMfNXPmTPXq1UtDhgyp0nVglcU1SRHkLmntIr/f3kIAAACcwrICp7zZ8Sg5y6eyRo0apffff1/79u3T5MmT1aJFC51//vmSpMcff1z/93//p3Hjxmnu3LlatmyZ+vTpo8LCwmprqgULFmj48OHq37+/Pv74Y33//fe67777qnUbpQVPdQuyLEv+MH6PnTBhgn744QcNGDBAn3/+udq2batp06ZJkm644QatX79e1157rVauXKkuXbromWeeCVsthKQIcrsCzU1GAgAAOPFceeWVcrlcmjp1ql577TVdf/31oeuTvv76aw0aNEjXXHONOnbsqObNm+vnn3+u9LrbtGmjLVu2aPv27aFp3377bZllvvnmGzVp0kT33XefunTpopYtW2rTpk1llomKilJxcfFRt7V8+XLl5uaGpn399ddyuVw69dRTK13zsQju35YtW0LTfvzxR2VlZalt27ahaa1atdIdd9yhmTNn6rLLLtPkyZND8zIyMnTTTTfpgw8+0F133aV///vfYalVIiRF1MGeJM63AwAAONEkJCRo6NChuvfee7V9+3Zdd911oXktW7bUrFmz9M0332j16tX6wx/+UGbktqPp1auXWrVqpZEjR2r58uX68ssvdd9995VZpmXLltq8ebPeeustrVu3Tk8//XSopyWoadOm2rBhg5YtW6Zdu3apoKCg3LaGDx+umJgYjRw5UqtWrdLcuXN166236tprrw2daldVxcXFWrZsWZnH6tWr1atXL7Vv317XXnutli9frkWLFmnEiBE6//zz1aVLFx04cEC33HKL5s2bp02bNunrr7/W4sWL1aZNG0nS2LFjNWPGDG3YsEFLly7V3LlzQ/PCgZAUQYxuBwAAcGIbNWqU9u7dqz59+pS5fuivf/2rzjjjDPXp00cXXHCB0tLSNHjw4Eqv1+Vyadq0aTpw4IC6du2qG264QQ8++GCZZS655BLdcccduuWWW9SpUyd98803Gj9+fJllhgwZor59++rCCy9UvXr1KhyGPC4uTjNmzNCePXt05pln6vLLL1fPnj317LPPHltjVGD//v06/fTTyzwGDhwoy7L04YcfKiUlRQMGDFDv3r3VvHlzvf3225Ikt9ut3bt3a8SIEWrVqpWuvPJK9evXTw888ICkQPgaM2aM2rRpo759+6pVq1Z6/vnnj7vew7GMqdl3Ns3JyVFycrKys7OP+aK26jZ+2gr9Z+EW3Xx+c/2pX/iS78nM5/Ppk08+Uf/+/cudR4vjR/uGH20cXrRv+NHG4XWit29+fr42bNigZs2aKSYmxu5yKuT3+5WTk6OkpCS5XPQnVLdItO+RjrPKZgM++Qg6OLpdjc6lAAAAwAmNkBRBwZDENUkAAACAcxGSIigYkooJSQAAAIBjEZIiyG0RkgAAAACnIyRFED1JAAAAUg0fNww2q47ji5AUQaGQxC8GAABwEgqOyJeXl2dzJajJgsfX8YwA6amuYnB09CQBAICTmdvtVkpKinbu3CkpcL8eq+RyBKfw+/0qLCxUfn4+Q4CHQTjb1xijvLw87dy5UykpKXK73VVeFyEpgghJAADgZJeWliZJoaDkNMYYHThwQLGxsY4LcDVBJNo3JSUldJxVFSEpgghJAADgZGdZltLT01W/fn35fD67yynH5/Ppiy++UI8ePU7IG/Y6Xbjb1+v1HlcPUhAhKYIISQAAAAFut7tavsxWN7fbraKiIsXExBCSwuBEaV9OtIwghgAHAAAAnI+QFEGMbgcAAAA4HyEpgjjdDgAAAHA+QlIEEZIAAAAA5yMkRRDXJAEAAADOR0iKIK5JAgAAAJyPkBRBnG4HAAAAOB8hKYIISQAAAIDzEZIiiGuSAAAAAOcjJEWQ201IAgAAAJyOkBRBJRmJgRsAAAAAByMkRZDbFWju4mJCEgAAAOBUhKQIcpe0Nj1JAAAAgHMRkiKI0e0AAAAA5yMkRZAneLqd3+ZCAAAAABwWISmCXMGBG/ykJAAAAMCpbA1JxcXFGj9+vJo1a6bY2Fi1aNFCf//732VKXbNjjNH999+v9PR0xcbGqlevXvrll19srLrqQj1JnG0HAAAAOJatIenRRx/VCy+8oGeffVarV6/Wo48+qscee0zPPPNMaJnHHntMTz/9tF588UUtXLhQ8fHx6tOnj/Lz822svGpcwYEbuCYJAAAAcCyPnRv/5ptvNGjQIA0YMECS1LRpU7355ptatGiRpEAv0lNPPaW//vWvGjRokCTptddeU2pqqqZPn66rrrrKttqrwsPADQAAAIDj2RqSzj77bE2aNEk///yzWrVqpeXLl+urr77SE088IUnasGGDduzYoV69eoXek5ycrG7dumnBggUVhqSCggIVFBSEXufk5EiSfD6ffD5fmPfoyPzFxZKkIr/f9lpqqmC70r7hQfuGH20cXrRv+NHG4UX7hh9tHF52t29lt2sZY99Ne/x+v/7yl7/osccek9vtVnFxsR588EHde++9kgI9Teecc462bdum9PT00PuuvPJKWZalt99+u9w6J0yYoAceeKDc9KlTpyouLi58O1MJOw9IDy7zKNZt9EjXYltrAQAAAE42eXl5uvrqq5Wdna2kpKTDLmdrT9I777yjN954Q1OnTlW7du20bNkyjR07Vg0aNNDIkSOrtM57771Xd955Z+h1Tk6OMjIy1Lt37yM2RCSs35mjB5d9K7k86t+/j6211FQ+n0+zZs3SRRddJK/Xa3c5NQ7tG360cXjRvuFHG4cX7Rt+tHF42d2+wbPMjsbWkHTPPffoz3/+c+i0ufbt22vTpk16+OGHNXLkSKWlpUmSMjMzy/QkZWZmqlOnThWuMzo6WtHR0eWme71e2w/0mKjA9v3G2F5LTeeEz7smo33DjzYOL9o3/Gjj8KJ9w482Di+72rey27R1dLu8vDy5XGVLcLvd8pfcR6hZs2ZKS0vTnDlzQvNzcnK0cOFCde/ePaK1VgcXAzcAAAAAjmdrT9LAgQP14IMPqnHjxmrXrp2+//57PfHEE7r++uslSZZlaezYsfrHP/6hli1bqlmzZho/frwaNGigwYMH21l6lYRGt7PvMjAAAAAAR2FrSHrmmWc0fvx43Xzzzdq5c6caNGigP/zhD7r//vtDy/zpT39Sbm6uRo8eraysLJ177rn67LPPFBMTY2PlVeOyAiHJGMnvN6GeJQAAAADOYWtISkxM1FNPPaWnnnrqsMtYlqWJEydq4sSJkSssTDylQlGR3yiKkAQAAAA4jq3XJJ1sSvcc+TnlDgAAAHAkQlIEHdqTBAAAAMB5CEkRFLwmSWKEOwAAAMCpCEkRVLoniZAEAAAAOBMhKYJcLkuWAuGIkAQAAAA4EyEpwoJn3BGSAAAAAGciJEWYu+QnN5QFAAAAnImQFGGhnqRiQhIAAADgRISkCHMHQxI9SQAAAIAjEZIi7OA1SX57CwEAAABQIUJShLlCIcneOgAAAABUjJAUYcEGL6InCQAAAHAkQlKEBXuSyEgAAACAMxGSIiwYkuhJAgAAAJyJkBRhoZ4kRrcDAAAAHImQFGGha5K4TxIAAADgSISkCDs4uh0hCQAAAHAiQlKEubiZLAAAAOBohKQIOzhwAyEJAAAAcCJCUoQFG9xPSAIAAAAciZAUYfQkAQAAAM5GSIowd+hmsoQkAAAAwIkISRFmWYFwRE8SAAAA4EyEpAjjZrIAAACAsxGSIoybyQIAAADORkiKMO6TBAAAADgbISnCQiGJa5IAAAAARyIkRRghCQAAAHA2QlKEEZIAAAAAZyMkRViwwQlJAAAAgDMRkiKMniQAAADA2QhJEcbodgAAAICzEZIijJ4kAAAAwNkISREWDEncTBYAAABwJkJShIUGbuB0OwAAAMCRCEkRdvB0O7+9hQAAAACoECEpwg6GJHvrAAAAAFAxQlKE0ZMEAAAAOBshKcLoSQIAAACcjZAUYaGBG+hJAgAAAByJkBRhLiswqh2j2wEAAADOREiKMG4mCwAAADgbISnCCEkAAACAsxGSIizY4EWEJAAAAMCRCEkRFuxJ8hOSAAAAAEciJEVYMCTRkwQAAAA4EyEpwkI9SYxuBwAAADgSISnCQj1JxYQkAAAAwIkISREWbHB6kgAAAABnIiRFGNckAQAAAM5GSIow7pMEAAAAOBshKcIISQAAAICzEZIijNPtAAAAAGcjJEVYaOAGQhIAAADgSISkCKMnCQAAAHA2QlKEcTNZAAAAwNkISRHGzWQBAAAAZyMkRRg9SQAAAICzEZIiLNjgXJMEAAAAOBMhKcJcViAcMbodAAAA4EyEpAhjdDsAAADA2QhJERYMScWEJAAAAMCRCEkRFmxwQhIAAADgTISkCAv1JDG6HQAAAOBIhKQI43Q7AAAAwNkISRF28GayfnsLAQAAAFAhQlKEBRucjiQAAADAmQhJEXZwCHB6kgAAAAAnIiRFWDAkkZEAAAAAZyIkRRg9SQAAAICzEZIiLNSTZCTDMOAAAACA4xCSIqx0gzMMOAAAAOA8hKQIc1sHn3NDWQAAAMB5CEkRZpUOSfQkAQAAAI5DSIowNyEJAAAAcDRCUoTRkwQAAAA4GyEpwhi4AQAAAHA2QlKEWdbBYcAJSQAAAIDzEJJs4C5JSYxuBwAAADgPIckGwZBUVExIAgAAAJyGkGSDYEjy05MEAAAAOA4hyQbukiHuirgmCQAAAHAcQpINQtckEZIAAAAAxyEk2YCQBAAAADgXIckGhCQAAADAuQhJNghek0RIAgAAAJyHkGSD0BDghCQAAADAcWwPSb/++quuueYa1alTR7GxsWrfvr2+++670HxjjO6//36lp6crNjZWvXr10i+//GJjxcePIcABAAAA57I1JO3du1fnnHOOvF6vPv30U/3444/617/+pVq1aoWWeeyxx/T000/rxRdf1MKFCxUfH68+ffooPz/fxsqPDzeTBQAAAJzLY+fGH330UWVkZGjy5Mmhac2aNQs9N8boqaee0l//+lcNGjRIkvTaa68pNTVV06dP11VXXVVunQUFBSooKAi9zsnJkST5fD75fL5w7UqlBLfvDmQkFTqgppom2J60a3jQvuFHG4cX7Rt+tHF40b7hRxuHl93tW9ntWsbYd85X27Zt1adPH23dulXz589Xw4YNdfPNN+vGG2+UJK1fv14tWrTQ999/r06dOoXed/7556tTp076v//7v3LrnDBhgh544IFy06dOnaq4uLiw7cuxeGy5W7/mWbqpTbHapNCbBAAAAERCXl6err76amVnZyspKemwy9nak7R+/Xq98MILuvPOO/WXv/xFixcv1m233aaoqCiNHDlSO3bskCSlpqaWeV9qampo3qHuvfde3XnnnaHXOTk5ysjIUO/evY/YEJHg8/k0a9Ys1UpJ0q95+9S5Sxdd0KqerTXVNME2vuiii+T1eu0up8ahfcOPNg4v2jf8aOPwon3DjzYOL7vbN3iW2dHYGpL8fr+6dOmihx56SJJ0+umna9WqVXrxxRc1cuTIKq0zOjpa0dHR5aZ7vV7HHOhuV8mlYJbbMTXVNE76vGsi2jf8aOPwon3DjzYOL9o3/Gjj8LKrfSu7TVsHbkhPT1fbtm3LTGvTpo02b94sSUpLS5MkZWZmllkmMzMzNO9E5OFmsgAAAIBj2RqSzjnnHK1Zs6bMtJ9//llNmjSRFBjEIS0tTXPmzAnNz8nJ0cKFC9W9e/eI1lqdXIQkAAAAwLFsPd3ujjvu0Nlnn62HHnpIV155pRYtWqRJkyZp0qRJkiTLsjR27Fj94x//UMuWLdWsWTONHz9eDRo00ODBg+0s/biEepK4TxIAAADgOLaGpDPPPFPTpk3Tvffeq4kTJ6pZs2Z66qmnNHz48NAyf/rTn5Sbm6vRo0crKytL5557rj777DPFxMTYWPnxcVnBniS/zZUAAAAAOJStIUmSLr74Yl188cWHnW9ZliZOnKiJEydGsKrwOnhNks2FAAAAACjH1muSTlbBwe3oSQIAAACch5BkA09JSipi4AYAAADAcQhJNig5205+QhIAAADgOIQkG9CTBAAAADgXIckGB69JIiQBAAAATkNIsoGHm8kCAAAAjkVIsoGLm8kCAAAAjkVIskGoJ6mYkAQAAAA4DSHJBm56kgAAAADHIiTZwG1xTRIAAADgVIQkG7gZuAEAAABwLEKSDQhJAAAAgHMRkmxASAIAAACci5Bkg+A1SUWEJAAAAMBxCEk2CPYk+RndDgAAAHAcQpINgjeTpScJAAAAcB5Ckg2CN5P1E5IAAAAAxyEk2cDFNUkAAACAYxGSbOBxM7odAAAA4FSEJBsEe5IISQAAAIDzEJJs4OE+SQAAAIBjEZJs4CIkAQAAAI5FSLKBhyHAAQAAAMciJNkgeE0SN5MFAAAAnIeQZAN6kgAAAADnIiTZwMXNZAEAAADHIiTZ4GBPkt/mSgAAAAAcipBkA3eoJ8nmQgAAAACUQ0iygduiJwkAAABwKkKSDdzukvskcUkSAAAA4DiEJBuUZCQV05MEAAAAOA4hyQZuV6DZi8lIAAAAgOMQkmzgLml1epIAAAAA5yEk2SA4ul0x90kCAAAAHIeQZIPg6HaEJAAAAMB5CEk2cIduJktIAgAAAJyGkGSDgzeTJSQBAAAATkNIsgE9SQAAAIBzVSkkbdmyRVu3bg29XrRokcaOHatJkyZVW2E1WfCaJL8hJAEAAABOU6WQdPXVV2vu3LmSpB07duiiiy7SokWLdN9992nixInVWmBNRE8SAAAA4FxVCkmrVq1S165dJUnvvPOOTjvtNH3zzTd64403NGXKlOqsr0ZiCHAAAADAuaoUknw+n6KjoyVJs2fP1iWXXCJJat26tbZv31591dVQhCQAAADAuaoUktq1a6cXX3xRX375pWbNmqW+fftKkrZt26Y6depUa4E1ESEJAAAAcK4qhaRHH31UL730ki644AINGzZMHTt2lCR99NFHodPwcHiEJAAAAMC5PFV50wUXXKBdu3YpJydHtWrVCk0fPXq04uLiqq24msoTDEmMbgcAAAA4TpV6kg4cOKCCgoJQQNq0aZOeeuoprVmzRvXr16/WAmsiV8kQ4MZwQ1kAAADAaaoUkgYNGqTXXntNkpSVlaVu3brpX//6lwYPHqwXXnihWgusiYI9SRK9SQAAAIDTVCkkLV26VOedd54k6b333lNqaqo2bdqk1157TU8//XS1FlgTuUqHJHqSAAAAAEepUkjKy8tTYmKiJGnmzJm67LLL5HK5dNZZZ2nTpk3VWmBN5CEkAQAAAI5VpZB0yimnaPr06dqyZYtmzJih3r17S5J27typpKSkai2wJgpekyRJRYQkAAAAwFGqFJLuv/9+3X333WratKm6du2q7t27Swr0Kp1++unVWmBNVLoniYEbAAAAAGep0hDgl19+uc4991xt3749dI8kSerZs6cuvfTSaiuupip9TRI9SQAAAICzVCkkSVJaWprS0tK0detWSVKjRo24kewx8LgsFfkN1yQBAAAADlOl0+38fr8mTpyo5ORkNWnSRE2aNFFKSor+/ve/y+/3V3eNNZKLG8oCAAAAjlSlnqT77rtPL7/8sh555BGdc845kqSvvvpKEyZMUH5+vh588MFqLbIm8rgsFUoqLiYkAQAAAE5SpZD06quv6v/9v/+nSy65JDStQ4cOatiwoW6++WZCUiW4LXqSAAAAACeq0ul2e/bsUevWrctNb926tfbs2XPcRZ0M3O6SkMTpiQAAAICjVCkkdezYUc8++2y56c8++6w6dOhw3EWdDEI9SWQkAAAAwFGqdLrdY489pgEDBmj27NmheyQtWLBAW7Zs0SeffFKtBdZU7pKBG4roSQIAAAAcpUo9Seeff75+/vlnXXrppcrKylJWVpYuu+wy/fDDD/rPf/5T3TXWSMGQREYCAAAAnKXK90lq0KBBuQEali9frpdfflmTJk067sJqOnqSAAAAAGeqUk8Sjp8n2JPE6HYAAACAoxCSbBK8mWwR90kCAAAAHIWQZJNgTxL3SQIAAACc5ZiuSbrsssuOOD8rK+t4ajmpuEJDgBOSAAAAACc5ppCUnJx81PkjRow4roJOFh43IQkAAABwomMKSZMnTw5XHScdNz1JAAAAgCNxTZJNgkOAE5IAAAAAZyEk2YSQBAAAADgTIckmB28mS0gCAAAAnISQZBM3N5MFAAAAHImQZBO3K9D03EwWAAAAcBZCkk1KRgDnZrIAAACAwxCSbBLsSWLgBgAAAMBZCEk2cZe0PCEJAAAAcBZCkk089CQBAAAAjkRIsomL+yQBAAAAjkRIsomHkAQAAAA4EiHJJsH7JDG6HQAAAOAshCSbuC16kgAAAAAnIiTZxO0mJAEAAABOREiySbAnqYiQBAAAADgKIckmwWuS/IQkAAAAwFEISTYJhiR6kgAAAABnISTZ5OAQ4H6bKwEAAABQGiHJJgdvJmtzIQAAAADKcExIeuSRR2RZlsaOHRualp+frzFjxqhOnTpKSEjQkCFDlJmZaV+R1YieJAAAAMCZHBGSFi9erJdeekkdOnQoM/2OO+7Qf//7X7377ruaP3++tm3bpssuu8ymKquXy+JmsgAAAIAT2R6S9u/fr+HDh+vf//63atWqFZqenZ2tl19+WU888YR+97vfqXPnzpo8ebK++eYbffvttzZWXD0O9iQRkgAAAAAn8dhdwJgxYzRgwAD16tVL//jHP0LTlyxZIp/Pp169eoWmtW7dWo0bN9aCBQt01llnVbi+goICFRQUhF7n5ORIknw+n3w+X5j2onKC2/f5fJIJnGbnK/LbXldNUqaNUe1o3/CjjcOL9g0/2ji8aN/wo43Dy+72rex2bQ1Jb731lpYuXarFixeXm7djxw5FRUUpJSWlzPTU1FTt2LHjsOt8+OGH9cADD5SbPnPmTMXFxR13zdVh1qxZ+uVXS5Jbm7Zs0SefbLK7pBpn1qxZdpdQo9G+4UcbhxftG360cXjRvuFHG4eXXe2bl5dXqeVsC0lbtmzR7bffrlmzZikmJqba1nvvvffqzjvvDL3OyclRRkaGevfuraSkpGrbTlX4fD7NmjVLF110kXYs+lUfbf5Z6ekN1b9/e1vrqklKt7HX67W7nBqH9g0/2ji8aN/wo43Di/YNP9o4vOxu3+BZZkdjW0hasmSJdu7cqTPOOCM0rbi4WF988YWeffZZzZgxQ4WFhcrKyirTm5SZmam0tLTDrjc6OlrR0dHlpnu9Xscc6F6vV1HeQNP7S16jejnp866JaN/wo43Di/YNP9o4vGjf8KONw8uu9q3sNm0LST179tTKlSvLTPv973+v1q1ba9y4ccrIyJDX69WcOXM0ZMgQSdKaNWu0efNmde/e3Y6Sq5W7ZOAGP6PbAQAAAI5iW0hKTEzUaaedVmZafHy86tSpE5o+atQo3Xnnnapdu7aSkpJ06623qnv37ocdtOFEEgxJRcWEJAAAAMBJbB/d7kiefPJJuVwuDRkyRAUFBerTp4+ef/55u8uqFh56kgAAAABHclRImjdvXpnXMTExeu655/Tcc8/ZU1AYeVyBW1QVFPltrgQAAABAabbfTPZklRwbuGgs5wBj8AMAAABOQkiySa34KEnSnrxCmysBAAAAUBohySa1S0LS3lx6kgAAAAAnISTZpHZcICTtLyhSQVGxzdUAAAAACCIk2SQxxhMaBjwrj94kAAAAwCkISTZxuSzVigsM3rAnl+uSAAAAAKcgJNmoVlzwuiRCEgAAAOAUhCQbMcIdAAAA4DyEJBvVpicJAAAAcBxCko1CPUkMAw4AAAA4BiHJRrXjAwM37OV0OwAAAMAxCEk2Cg7cwOh2AAAAgHMQkmxUu+R0O3qSAAAAAOcgJNno4DVJhCQAAADAKQhJNmJ0OwAAAMB5CEk2qs19kgAAAADHISTZKHi6Xb7Pr7zCIpurAQAAACARkmwVH+VWlDvwEXBdEgAAAOAMhCQbWZZ1cIQ7bigLAAAAOAIhyWa1uC4JAAAAcBRCks1qx3slMcIdAAAA4BSEJJvViuNeSQAAAICTEJJsFromidPtAAAAAEcgJNmMniQAAADAWQhJNqMnCQAAAHAWQpLNQqPb0ZMEAAAAOAIhyWa147hPEgAAAOAkhCSb1SoZApz7JAEAAADOQEiyWeiapNxCGWNsrgYAAAAAIclmwdHtivxG+wqKbK4GAAAAACHJZjFet+Ki3JICvUkAAAAA7EVIcgDulQQAAAA4ByHJAbhXEgAAAOAchCQHOHivJIYBBwAAAOxGSHKA2nGBYcC5JgkAAACwHyHJAUI9SZxuBwAAANiOkOQAteMO3isJAAAAgL0ISQ5w8JokQhIAAABgN0KSAzC6HQAAAOAchCQH4D5JAAAAgHMQkhzgYE8SQ4ADAAAAdiMkOUCt+MAQ4Fl5hSr2G5urAQAAAE5uhCQHCJ5u5zdSzgF6kwAAAAA7EZIcwOt2KTHGI4l7JQEAAAB2IyQ5RPC6pN37CUkAAACAnQhJDpFRK06StP63/TZXAgAAAJzcCEkOcWpaoiRpTeY+mysBAAAATm6EJIc4NbUkJO0gJAEAAAB2IiQ5RLAn6Wd6kgAAAABbEZIcomVqgixL2rW/ULv2F9hdDgAAAHDSIiQ5RFyUR41rBwZv4JQ7AAAAwD6EJAfhuiQAAADAfoQkB2mdRkgCAAAA7EZIcpBWJSHpJwZvAAAAAGxDSHKQYE/SL5n75Pcbm6sBAAAATk6EJAdpWideUW6X8gqLtXXvAbvLAQAAAE5KhCQH8bhdalE/QZK0hlPuAAAAAFsQkhzm4OANOTZXAgAAAJycCEkOc2pw8AZGuAMAAABsQUiKpIJ9iiv4TSr2HXaR4L2SfuZ0OwAAAMAWhKQI8vzfabrox7uk7C2HXSbYk7T+t1wVFvkjVRoAAACAEoSkSIqtJUmyDuw97CLpyTFKjPGoyG+0ftf+SFUGAAAAoAQhKZJKQpIO7DnsIpZlhU65W8N1SQAAAEDEEZIiyMTVDjw5Qk+SxOANAAAAgJ0ISZEUGwhJ1hF6kqSDIYmeJAAAACDyCEkRZEpCkvKOHJI6NkqRJC1Yt1u5BUVhrgoAAABAaYSkSKrENUmS1KFRsprVjdcBX7E+XbUjAoUBAAAACCIkRVJc8HS7I1+TZFmWLju9oSTpg6Vbw14WAAAAgIMISRFkKtmTJEmXnhEISQvW79avWQfCWRYAAACAUghJkRQcuCHvyD1JktSoVpzOal5bxkjTv/813JUBAAAAKEFIiqTgwA2V6EmSpCFnNJIkvb9kq4wx4aoKAAAAQCmEpAg6eJ+kyoWkfu3TFet1a/2uXC3bkhW+wgAAAACEEJIiKXi6XVG+VJh31MUToj3qe1qaJOl9BnAAAAAAIoKQFElRCfLLHXh+jKfc/Xf5dhUUFYerMgAAAAAlCEmRZFkq9CQEnh/lhrJB3VvUUVpSjLIP+BjAAQAAAIgAQlKEhUJSJXuS3C5LN5zXTJL02GdrlJ3nC1dpAAAAAERIirhj7UmSpJFnN9Up9RO0O7dQT87+OUyVAQAAAJAISRFX6A6GpN2Vfo/X7dIDl7STJL22YKN+3JYTjtIAAAAAiJAUcQdPtzv6DWVLO+eUuhrQPl1+I/3to1XcNwkAAAAIE0JShPncx366XdB9A9oo1uvW4o17NX0ZgzgAAAAA4UBIirBjHbihtAYpsbrld6dIkv7x8Wrt2l9QnaUBAAAAECEp4go9iYEnVehJkqQbzmumU1MTtTu3UPdNW8lpdwAAAEA1IyRF2PH0JElStMetJ4Z2lNdtacYPmfpgKafdAQAAANWJkBRhVRnd7lDtGiRrbK9WkqQJH/2gX7MOVEdpAAAAAERIiriD90k6ttHtDvWHHs11euMU7Sso0j3vLpffz2l3AAAAQHUgJEVYqCepIFsqLqryejxul564spNivW59s263pi7aXE0VAgAAACc3W0PSww8/rDPPPFOJiYmqX7++Bg8erDVr1pRZJj8/X2PGjFGdOnWUkJCgIUOGKDMz06aKj5/PE3/wxTHeK+lQzerG6099T5UkPT5jjfbkFh7X+gAAAADYHJLmz5+vMWPG6Ntvv9WsWbPk8/nUu3dv5ebmhpa544479N///lfvvvuu5s+fr23btumyyy6zserjYyy3TExK4EUVB28o7dqzmqh1WqKyD/j0+Iyfjnt9AAAAwMnOY+fGP/vsszKvp0yZovr162vJkiXq0aOHsrOz9fLLL2vq1Kn63e9+J0maPHmy2rRpo2+//VZnnXWWHWUfv9haUn7WcQ3eEORxu/T3wafpihcX6K3FWzT0zMbqlJFy3OsFAAAATla2hqRDZWdnS5Jq164tSVqyZIl8Pp969eoVWqZ169Zq3LixFixYUGFIKigoUEHBwZus5uTkSJJ8Pp98Pl84yz+q4Pb9MbXk1gYV7ftNphpq6tQwUYM7pmv68u0aP32l3h3dTW6XddzrPREF29juz7qmon3DjzYOL9o3/Gjj8KJ9w482Di+727ey27WMQ+5G6vf7dckllygrK0tfffWVJGnq1Kn6/e9/Xyb0SFLXrl114YUX6tFHHy23ngkTJuiBBx4oN33q1KmKi4sLT/HHqNu6fyktZ7m+bzxKm+ucXy3rzCmUHlzmVn6xpaHNi3V2qiM+VgAAAMAx8vLydPXVVys7O1tJSUmHXc4xPUljxozRqlWrQgGpqu69917deeedodc5OTnKyMhQ7969j9gQkeDz+TRr1izVzWgp/bBcHU5pqNO696+29R+ov0kPfbpGM3fE6N6rz1N8tGM+3ogJtvFFF10kr9drdzk1Du0bfrRxeNG+4UcbhxftG360cXjZ3b7Bs8yOxhHfom+55RZ9/PHH+uKLL9SoUaPQ9LS0NBUWFiorK0spKSmh6ZmZmUpLS6twXdHR0YqOji433ev1OuZAt+LrSJLcBdlyV2NN15/bXG8s2qJNu/P03vfbdcN5zatt3ScaJ33eNRHtG360cXjRvuFHG4cX7Rt+tHF42dW+ld2mraPbGWN0yy23aNq0afr888/VrFmzMvM7d+4sr9erOXPmhKatWbNGmzdvVvfu3SNdbvWJDYQk5R3/6Haledwu/fH8FpKkSV+sV76vuFrXDwAAAJwMbA1JY8aM0euvv66pU6cqMTFRO3bs0I4dO3TgwAFJUnJyskaNGqU777xTc+fO1ZIlS/T73/9e3bt3P3FHtpMCo9tJ1R6SJOmyMxopPTlGO/cV6L0lW6t9/QAAAEBNZ2tIeuGFF5Sdna0LLrhA6enpocfbb78dWubJJ5/UxRdfrCFDhqhHjx5KS0vTBx98YGPVx8/EBUbvq477JB0qyuPSH3oETrN7cf46+Yr91b4NAAAAoCaz9ZqkygysFxMTo+eee07PPfdcBCqKkDD2JEnSVV0b69m5a7V17wF9uGybLu/c6OhvAgAAACDJ5p6kk5WJDV9PkiTFeN0adW6gN+n5eWtV7Gc4cAAAAKCyCEl2CIWkvVKYblN1zVmNlRzr1frfcjXjhx1h2QYAAABQExGS7BA83c5fJBVUbqz2Y5UY49Xwbo0lSR8u+zUs2wAAAABqIkKSHbyxkjcu8Dxvd9g20799uiRp/s+/6UAhw4EDAAAAlUFIskvwlLu8vWHbRLsGSWqYEqt8n19frd0Vtu0AAAAANQkhyS5xJafchWnwBkmyLEsXtU2VJM3kuiQAAACgUghJdgn1JIUvJElS73aBkDR7daaKuGcSAAAAcFSEJLvE1Qn8DGNPkiR1bVpbybFe7c3z6btN4Tu1DwAAAKgpCEl2iYtMT5LH7VLPNvUlSTN/yAzrtgAAAICagJBkl9DpduEb3S6od9s0SdLMH3fIhOm+TAAAAEBNQUiyS7AnKcyn20lSj1Z1Fe1xaeveA1q9fV/YtwcAAACcyAhJdkkInAKnnG1h31RclEc9WtWTFOhNAgAAAHB4hCS71D018PO3NVIEToHrHRoKnOuSAAAAgCMhJNmlzimS5ZLys6T9O8O+uZ5tUmVZ0o/bc7Rrf0HYtwcAAACcqAhJdvHGSLWaBZ7/9lPYN1c7Pkqn1EuQJC3bnBX27QEAAAAnKkKSneq1Dvz8bU1ENtcpI0WS9P0W7pcEAAAAHA4hyU71gtclrY7I5k5vXEuStGxLVkS2BwAAAJyICEl2sqknafmWbBX7uV8SAAAAUBFCkp1CPUnhvyZJklqlJiguyq39BUVa99v+iGwTAAAAONEQkuxUt5UkS8rbLeXuCvvmPG6X2jdMliR9v5nrkgAAAICKEJLsFBUn1WoSeB6h3iSuSwIAAACOjJBkt9B1SZEJSaER7hgGHAAAAKgQIcluoeuSIjN4w+mNUyRJP2fuU25BUUS2CQAAAJxICEl2i3BPUmpSjBokx8hvpBVbsyOyTQAAAOBEQkiyW4R7kqSD1yVxU1kAAACgPEKS3eq2Cvzcnynl7YnIJoPXJS3juiQAAACgHEKS3aITpeSMwPMIX5f0/ZYsGcNNZQEAAIDSCElOEOHrkk5rmCyPy9Jv+wq0LTs/ItsEAAAAThSEJCeI8HVJMV632qQnSeKmsgAAAMChCElOEOGeJInrkgAAAIDDISQ5QSgkRXKEuxRJgeuSAAAAABxESHKCeiUj3O3bJuVH5t5FwZ6kVb9mq7DIH5FtAgAAACcCQpITxCRLiQ0Cz3esisgmm9WNV3KsVwVFfv20Iyci2wQAAABOBIQkp2h6buDn6o8isjnLsg5el8QpdwAAAEAIIckp2l8e+PnDNMlfHJFNhq5LYvAGAAAAIISQ5BTNL5RiUqT9mdLGryKySXqSAAAAgPIISU7hiZLaDgo8X/V+RDYZDEkbduVqb25hRLYJAAAAOB0hyUlOGxL4+eOHUlH4Q0tKXJSa142XJC3bmhX27QEAAAAnAkKSkzQ9V0pIk/KzpPVzI7LJTlyXBAAAAJRBSHISl1tqd2ng+cr3IrLJ07kuCQAAACiDkOQ0wVPu1nwiFeaFfXOnN64lSVq2ea/8fhP27QEAAABOR0hymkZdpJTGUuF+6ZcZYd/cqWmJiva4lJNfpA27cwMTiwqkb56RsjaHffsAAACA0xCSnMayDvYmRWCUO6/bpQ6NkiWVui5p4UvSzL9KsyeEffsAAACA0xCSnKj1wMDPjV9Jfn/YN3fwfkl7AxM2zA/83L487NsGAAAAnIaQ5ETpHSRPrHRgr7R7bdg3F7wu6fvNWVJxkbT528CMPesl34Gwbx8AAABwEkKSE7m9UsPOgedbFlb+fcZIi/4t/TD9mDYX7En6acc+Hdi8NHA9lCQZv7Tr52NaFwAAAHCiIyQ5VUbXwM9jCUmbF0if3C29d720q/I9UOnJMWpSJ07FfqM1Cz8rO3Pn6spvHwAAAKgBCElOldEt8HPLosq/Z+lrgZ+mWJr7YKXfZlmWru7aWJJUsO6LwERPbODnzh8rv30AAACgBiAkOVWjMwM/d62R8vYcffn87LKn2f3wgbR9RaU3d2WXDMV6pDaFqwITOlwR+ElPEgAAAE4yhCSniq8j1WkZeL71u6Mvv/I9qeiAVK/1wSHEP/97pTdXKz5Ko1vlKsk6oAOueKnD0MAMQhIAAABOMoQkJwudcnfIdUm//Vy+dyl4qt0ZI6QL75Mst/TLTGnTgkpv7sp6gZvHLixqpd0JJQEte4uUn1OV6gEAAIATEiHJySoavOHXJdLzZ0kvnC3t3RiYtn2FtH2Z5PJKHa6S6rSQzrg2MG/OxMCod5XQMGupJGlBcWu9tXKflNggMOO3n45/XwAAAIATBCHJyYI9Sb8uCdy/SJI+/0dgYIZ926XXBkk526Xv/xOY13pA4DQ9SerxJ8kdLW3+Rlo75+jb8vulTV9Lkhb622jqws0y9dsE5jF4AwAAAE4ihCQnq9tKikmWfHlS5ipp49fSus8DPUYpjQM9Sf8ZLK14O7D8GSMOvje5odT1xsDzOQ8EQtCR7PxBys+S8cZra0xL/Zp1QJvcTUrmcV0SAAAATh6EJCdzuaRGpU65+/wfgednjJBG/jdwOtxvPwVGtkvOkJpfWPb9594pRSVIO1ZIqz888rY2BnqRrMbdNOTMZpKkKWsZBhwAAAAnH0KS0wVPuVvwXODUOXe01ONuqVZTacR0Ka7k9LrTrwmEqtLi60jdbwk8//zBg6fsVWTTV4GfTc7RHy9ooXYNkrTkQLokqXD7D9W2OwAAAIDTEZKcLjh4Q9amwM8zR0lJJQMq1DtV+v1nUs/7pbNvq/j93cdIsbWl3b9Iy9+seJnffpbWzw88b3qeUuKi9Obos1Sr8WnyG0tR+bs1bym9SQAAADg5EJKcrmFnySr5mLxx0rl3lJ1fr5V03l1SVFzF749Jks67M/B83iNSUUHZ+XvWS69dIhXkSOmdAtuTlBTj1aQbemiXN9CbNOm9jzV14eZq2ikAAADAuQhJThedIKW1Dzzv9gcpof6xr+PMGwLXL+VslRa/fHB61mbp1UsCI+XVayNd84Hk9oRmx3jdqtu8kySppbVVf5m2Uo/P+EmmkkOKa8966btXpMK8Y68ZBx1t0A0AAABUK0LSiaDf49I5Y6Xz7q7a+72x0vl/Cjyfca/0eEvp1YHS5AGBm8XWOUUa8eHB4cNLcaW2lSQNaRS4oexzc9fpzneWq7DoKF/cc3dJk/tLH98hvTVM8h2oWu0nu61LpCfbSh/dWun7XQEAAOD4EJJOBI27SRc9EOhVqqrTr5FOHRB4nrtT2vCFlL1ZSmkijfhISkyt+H0l90rqELVNj13eQR6XpWnf/6q+//eFpn2/VUXFFYQlv1+adlOgh0qS1s+T3r5G8uVXvf6T0YG90rvXBdpx6WvSokl2VwQAAHBS8Bx9EdQIbq80bKpUsE/a9bO08ycp51ep0/DAPZUOp36gJ0k7V+vKzo2UlhSj2976Xut/y9Udby/X2zO/1Ii2HnmbdldSfKyS47yqv2KSaq+dJeOO1r4L/q7E+RNkrZ0t31vXyDfkVbmjYuS2LLldlizLisz+O4kx0ralUmGu1KzH4ZeZPiYQZKMSpML90oz7pEZnSg3PiGy9kWKMtHWxtPq/UlJDqevo8iM2AgAARAAh6WQTnRgYnKFkgIajqnOK5PIEBnb4eKx6tL9CX97dQ7NnfqSUZZN0ft53ci0x2vpdXb1S1E8/mQy96n1UsqT78q/R1P81UnfXHXrF+7hi183Sj4+cqzeKe+qT4m7arzi5LMnjcsntsso/SoKUx33wudtlyWVZKp2t3C5L0R6XYrxueV2Wdu506cM930uWJWOM/EaK9uep3YEl2udK0tqoViow0bKswHs9Lkset6vsz5Ltlq6tsjxuS1FuV8l7Jb+R/MYoyrdPp+78VO0zp6l+3lpJ0o91++jz5n9SoSdRsixZkixLOv3XN3X+hv+p2PLq/dNeVOfNL6vFrrnK/s+1ev/MN+TzJJZpB5dlyWVJLldwHWXbKVj9wddlZxycb8ldlKt6e5aq7u6lqrvnOyXtW6s9tU/X2ubXaEftblr+m6Wi5dvl8bhD7znSNg5XgxTYVsqe5aq740ulbf1MsXnbQu1Y+PMcea+YJCu2VqXbHgAAoDoQknBkniipxe+kX2ZKS6ZIS6YoMSpBlxbuD8y3pDwrXo20S/d7/xN626f+7npPveR2SQv87XSD7y79P++/1NG1Xh1d6/WA51V95T9NsSpQqpWlVGuvchSn5UXNtcx/ilaZZtpnYlUst3xyy5IUqwLFqlBRlk8FxqtcxShPMYqST7WtPUq3dquesrVHidqYnaZNpr7qKVtD3fN0sXuB4q3AyH6Fxq0VpoVW+ptpr0nUPsVqn+LkN5a8VrG8KpJfLv1q6mqTqa+tpp6K5Fa0fIpXvmJUKJ/cKpRXBfKqUF75S85c9ahIZ1i/6Hz3cp3nWqlG1m/yyC+PihWtQrmtwHVF+cYrj4rVdtcMJf22RHcU3qwlppXStVsdXOt1s/dZyZImFA7Xf75xKUnD9L+oVcrI36oG8+7WP4uu0FZTT/mKLvNxueQPtVOsla9i41aO4pSrGJkjnl1rdLq1VkPdc9WvVFsFpWXOV1rmfK3xN9Ka4h6auX6pdpha2mFqK1vxyleUJEuJytMFrmW6yL1E57pWar+J1QrTQsv9zbXBpKuWtU/1laU0a486uNarnbVRHuvgKZv7TYy+9p+mC1zLFb1+pjY/2k2PJf9VO6Kaqq7Zo7r+3fJbbmV6GynfkyBXBT2RjQo36Oy8z9Uu/3ttiWqmL+J76+eo00pCc6WO+pIWObZrwCq7bpcpVpLJVlRiPaXWSlB6UoxqxUeF5vuLi7VslyX/iu3yeA7+ii4XcKUyfywoH0JLTz3cslYFS5bsT+nnJTtnQq8Pt2RJWLcsuVyBn1G+HCXu/UFWQn2pXmvFRnsV7XFVqRe5Kv3Oh27G5ytSVoG0PTtfXm/F946zKthSReVWWE+Fy1V9fRW1U8XLVW67h2vE6qzH5ytSQbGUV1gkryl9jFWuHSpfnz3terj3A6hZLFPpocpOTDk5OUpOTlZ2draSkpJsrcXn8+mTTz5R//795fV6ba3lmBQXSRvmSaumST/9V8rPljwxUserpLNullIaS8vfkhY8K+1eK9VqJv1hvhSTLCnwBavYb1Scs03WirflXvGW3Lt/jvhu7I/PkLsoX7EFvx3T+/xyyVguuc3hb8brl1tFrihZxi+vKTjscpkxzbWk7iCtqN1HdQs267INE1S7cJv8smTkklvFoWVXJl+gNzImysiSkVGj3B81ZsOYMsvkuGup2PIqyp+vKHNAXuM7TH2WCqxYSYEgZcmvYnl0wBWvPFe8vKZQqUUHe3F+c6fqp5gOWhN1mrZ5G+usvHk6L3emYk3FA3AUy6V8K1bRJl+eUvVVxm+uevrBe5oWRp+tJVFdVGBFq3b2j/p7wSNqZO1SkXHJkgkFzND7TLLWm3TtM7EqkFf5ilJba5PauLaU28ZGf6rm+zvILb9irULFqEDuki/3loz8snRA0co3UTqgaPllyZKRVdJeweUsGcXIpwQrTwnKV4xVKL9xySe3iuVSlIqUbOUqWbmKs/KVa2KUpQRlm3hFWUVqaO1SmvbIY/lVYDzaYNK11jRUjolVQ2u3Gli7lWbtkZFUoKjAfpmo0P7lmyjtV6yyTbyyFa88xShaPkWrUNEqVJE8ylOM8ky0CuVRrFWgeOUrXvlyy69iueSXS8UlD3+Zn5b8wefm4HQjyV0S9N1WsTwlS3lULFdJ2wXfF3geeNRVjjq7ftaprq2hz2G3SdRCfxut8jdTlOVTgg4oXoFrFQvlUaG8KpRHBSYq9LooDJfOBvfHqyJFW0WqpyylW7uVbu1RnPK1TXW1xV9PW0x95SlaLvnlLvn8C+WRTx4VyS23ihWjQsXIJ49VpEJT8jkpEHq9Kip5FMvIUrFcKpJLMfKpjpWjWtY+JSlP+xSr30yKdplk7Vdsyfb8cqtYtUv+sFDPylaCdUA+4yn5I41HOYrXXpOoPSV/7PFXsq3ilK9a1n6laL8SrAPKMfHaqwTtNYnKV5TcKpY79Dn7Dz63ikO1uUraosAE9rewgr+5mgpix6HTPCpSLe1XihV4uOUPHAfGU/JHKE/odWHp1/KUWZdbfkXJpyj5Av8mrKKS14Hf2/sVo1wT+MPakdrJOsofR442v/zy5bkqWkeZP1gEfzdVvEJLRsZvZLmCvfjl/8ThKnlY8kuyVBT6d+4O/dsukrvMRqxDfnpVpBgVKlb5iraKlG+ilKcY5SpGhfJWWOFhQ2WlJ1a02LFsx8gtv2JUqCgVKkpFJa1Q9vdd8N9j6HeX5Sp7XBipqNgnj8dbptQjbfdwu3ZwXsX7caRjqvS88sG84vcd+jkGt3Poeyts1wrWfehSlkyFDWGVnn+YN9dJa6pR191g+/fhymYDQlIE2X1QVIuiAmn7Cql28/Kj4fn90paFUt1WFY6UFxK8Jmfzt1JcHSkxTUpMl/bvlH79Ttr6nbTzx8C2in2SvyjwD9IbFwhnnmipKD8wtHhhbmBecoaU3FD+uLrK3PCD0rx5svZulFxuqd2l0unXSo3PCmx/7wZp0wLpt9VSfk7gVML8wOh9ckcFhkEv9kl7N0l7N0pFhwQDd7Tk90nmMCP8xdUJ9L6d0ktK63BwnZ4YKSG17C+Xgn3SJ3+Slk8NvHZ5AvvS+Cyp36OhoBnywzTpy38FaivIOcIHZQVGNSz2BWqtDE9soK3OGBHY/qG/BPOzVbzkNWUumq60eCPX/h3Svh2SOSQU1W0lndpfatU38Dlt+z7weWdtluLrSQlpgYFC6rUJbCclo8Jy8rN/U/F7oxS/JXCjY7/lVX5sfbn8PsXk7zzsbvgtj3aknq8daReq9p7v1fDXT+UtZhh6O213pSrFn6VYHf4PCACAmm1FzJnq8OfZtn8fJiSVICSdXMq0sdsdCDLu4zir1Bhpf6bkLw6MLhiVEAheUqCHrbggEOaKCgKBQEZKaXrsAw7s3RS4aXBSg4PrP1pdB/YGgofxS1HxgVDkjQ/cWNgTEwg5xgTqys8JDP4gBdZvuaXiwkCvYEFOoP7GZ5UPZYcodwz7/ZIvVyrYHwisnqhAz2J1MSZwv62oeCm+/sF2zc8J9Fru3RDYri8/EGbj6gQCWlztg+sozA0MBrFzdaCNPDGBny63An+WtQJt6MuXfHmBh/GXzHOVhEXr4E9vjBSVGLi+zxsbCIn+4kAg9UQH2jAmJVBz4f7A53Rg78EAnJIR2JecrdJvP0u71gTaL7mRlJIhX1x9zZ//hc4/5yx5VRT4/IL758uXCrKlA1lSflbgDwWemEBNnphADb68wHaLCgI1RJU6bk1x4DML1hz66Q88ykwrWVYmULvLE1hH6Z+yDr7X+AOflylZnzcuMNBIRjcpoZ5UVBgIzBu/lHb9EjhOoxMDbWnp4L+j4sKyPw8N4cfJ7/dr2/ZMNchoIpcnKvBHjPh6gQFskhoG6s7eEvg3mbUpUIflPnhTb39RYFpxYaAdPLGB9nd5A78Pgp+VVPIHkqiSttfBtvVESXF1A8drTHLg3+D+TGn/b4HPruTfqHG5pdhagT8sJNSXohNl/MUlbRP492vl7ZbJ2yXrkD+aBP5nr+C/d2OkqDiZ2NpSXB2ZqITQepS3W1ZxoYzLJVmlPmfLJWOV+uwtV+BR7JOKDsgqyg/UVLJJvzHK3LFDqampcrlK/V25oq8bLrdMTC2Z2FqBmix3oB2LC2WFfr8WSsUFsoLtXhx4fciKJE+MjDtK8kTLuKMld7SMJ1oyflmFubIK90u+/Yf7A/xRHfnv9kdgHaav4NCJFfx1vlyTWZLfb7RzZ6bq1w+0b0XrMsHPSVZgpr9Ylik6+O89+LqibQS5vDLeOPm9cYHjuChfrsL9sny5gc/iMCrfvJVb8pi/pbo88rtjZDzRMi5vYDvGyCr1+y743JI/9DvRMn6Zks/AGKPsrGwlpySX6sGp+LOuXHlHPk4q6nU9+Far4n/KwXlHrObI/VRHdoT9PXS7FRzLFcWL4rQOqjtwou3fhyubDbgmCTWXy6XjHuXesgI9XRVxewKPqPjj24Yk1Wpy7HXF1S4bBg63nDc28NBhhnk/Hi5X4ItudGL1r1sK1F+nRfnpMUmBUf4qM9JfVHzg1FCnqdU08GjVu+x0n0+5Mb9Iqe2kmvTHFE9U4HYGjbvZWkaxz6cln3yi1P795Tps+3aPaE2HU+E1MscxLVL8JW3cv39/uWvSMewQPp9PK/iDa1j5fD59Rxuf9BhfFwAAAABKISQBAAAAQCmEJAAAAAAohZAEAAAAAKUQkgAAAACgFEISAAAAAJRCSAIAAACAUghJAAAAAFAKIQkAAAAASiEkAQAAAEAphCQAAAAAKIWQBAAAAAClEJIAAAAAoBRCEgAAAACUQkgCAAAAgFIISQAAAABQCiEJAAAAAEohJAEAAABAKR67Cwg3Y4wkKScnx+ZKJJ/Pp7y8POXk5Mjr9dpdTo1EG4cX7Rt+tHF40b7hRxuHF+0bfrRxeNndvsFMEMwIh1PjQ9K+ffskSRkZGTZXAgAAAMAJ9u3bp+Tk5MPOt8zRYtQJzu/3a9u2bUpMTJRlWbbWkpOTo4yMDG3ZskVJSUm21lJT0cbhRfuGH20cXrRv+NHG4UX7hh9tHF52t68xRvv27VODBg3kch3+yqMa35PkcrnUqFEju8soIykpiX90YUYbhxftG360cXjRvuFHG4cX7Rt+tHF42dm+R+pBCmLgBgAAAAAohZAEAAAAAKUQkiIoOjpaf/vb3xQdHW13KTUWbRxetG/40cbhRfuGH20cXrRv+NHG4XWitG+NH7gBAAAAAI4FPUkAAAAAUAohCQAAAABKISQBAAAAQCmEJAAAAAAohZAUQc8995yaNm2qmJgYdevWTYsWLbK7pBPSww8/rDPPPFOJiYmqX7++Bg8erDVr1pRZ5oILLpBlWWUeN910k00Vn1gmTJhQru1at24dmp+fn68xY8aoTp06SkhI0JAhQ5SZmWljxSeepk2blmtjy7I0ZswYSRy/VfHFF19o4MCBatCggSzL0vTp08vMN8bo/vvvV3p6umJjY9WrVy/98ssvZZbZs2ePhg8frqSkJKWkpGjUqFHav39/BPfCuY7Uvj6fT+PGjVP79u0VHx+vBg0aaMSIEdq2bVuZdVR03D/yyCMR3hPnOtoxfN1115Vrv759+5ZZhmP48I7WvhX9TrYsS48//nhoGY7hw6vMd7PKfH/YvHmzBgwYoLi4ONWvX1/33HOPioqKIrkrIYSkCHn77bd155136m9/+5uWLl2qjh07qk+fPtq5c6fdpZ1w5s+frzFjxujbb7/VrFmz5PP51Lt3b+Xm5pZZ7sYbb9T27dtDj8cee8ymik887dq1K9N2X331VWjeHXfcof/+97969913NX/+fG3btk2XXXaZjdWeeBYvXlymfWfNmiVJuuKKK0LLcPwem9zcXHXs2FHPPfdchfMfe+wxPf3003rxxRe1cOFCxcfHq0+fPsrPzw8tM3z4cP3www+aNWuWPv74Y33xxRcaPXp0pHbB0Y7Uvnl5eVq6dKnGjx+vpUuX6oMPPtCaNWt0ySWXlFt24sSJZY7rW2+9NRLlnxCOdgxLUt++fcu035tvvllmPsfw4R2tfUu36/bt2/XKK6/IsiwNGTKkzHIcwxWrzHezo31/KC4u1oABA1RYWKhvvvlGr776qqZMmaL777/fjl2SDCKia9euZsyYMaHXxcXFpkGDBubhhx+2saqaYefOnUaSmT9/fmja+eefb26//Xb7ijqB/e1vfzMdO3ascF5WVpbxer3m3XffDU1bvXq1kWQWLFgQoQprnttvv920aNHC+P1+YwzH7/GSZKZNmxZ67ff7TVpamnn88cdD07Kyskx0dLR58803jTHG/Pjjj0aSWbx4cWiZTz/91FiWZX799deI1X4iOLR9K7Jo0SIjyWzatCk0rUmTJubJJ58Mb3E1REVtPHLkSDNo0KDDvodjuPIqcwwPGjTI/O53vyszjWO48g79blaZ7w+ffPKJcblcZseOHaFlXnjhBZOUlGQKCgoiuwPGGHqSIqCwsFBLlixRr169QtNcLpd69eqlBQsW2FhZzZCdnS1Jql27dpnpb7zxhurWravTTjtN9957r/Ly8uwo74T0yy+/qEGDBmrevLmGDx+uzZs3S5KWLFkin89X5lhu3bq1GjduzLFcRYWFhXr99dd1/fXXy7Ks0HSO3+qzYcMG7dixo8xxm5ycrG7duoWO2wULFiglJUVdunQJLdOrVy+5XC4tXLgw4jWf6LKzs2VZllJSUspMf+SRR1SnTh2dfvrpevzxx207jeZENW/ePNWvX1+nnnqq/vjHP2r37t2heRzD1SczM1P/+9//NGrUqHLzOIYr59DvZpX5/rBgwQK1b99eqampoWX69OmjnJwc/fDDDxGsPsAT8S2ehHbt2qXi4uIyH7okpaam6qeffrKpqprB7/dr7NixOuecc3TaaaeFpl999dVq0qSJGjRooBUrVmjcuHFas2aNPvjgAxurPTF069ZNU6ZM0amnnqrt27frgQce0HnnnadVq1Zpx44dioqKKvfFJzU1VTt27LCn4BPc9OnTlZWVpeuuuy40jeO3egWPzYp+Bwfn7dixQ/Xr1y8z3+PxqHbt2hzbxyg/P1/jxo3TsGHDlJSUFJp+22236YwzzlDt2rX1zTff6N5779X27dv1xBNP2FjtiaNv37667LLL1KxZM61bt05/+ctf1K9fPy1YsEBut5tjuBq9+uqrSkxMLHcqOcdw5VT03awy3x927NhR4e/p4LxIIyThhDZmzBitWrWqzDUzksqcg92+fXulp6erZ8+eWrdunVq0aBHpMk8o/fr1Cz3v0KGDunXrpiZNmuidd95RbGysjZXVTC+//LL69eunBg0ahKZx/OJE5fP5dOWVV8oYoxdeeKHMvDvvvDP0vEOHDoqKitIf/vAHPfzww4qOjo50qSecq666KvS8ffv26tChg1q0aKF58+apZ8+eNlZW87zyyisaPny4YmJiykznGK6cw303O9Fwul0E1K1bV263u9wIHpmZmUpLS7OpqhPfLbfcoo8//lhz585Vo0aNjrhst27dJElr166NRGk1SkpKilq1aqW1a9cqLS1NhYWFysrKKrMMx3LVbNq0SbNnz9YNN9xwxOU4fo9P8Ng80u/gtLS0cgPpFBUVac+ePRzblRQMSJs2bdKsWbPK9CJVpFu3bioqKtLGjRsjU2AN07x5c9WtWzf0e4FjuHp8+eWXWrNmzVF/L0scwxU53Hezynx/SEtLq/D3dHBepBGSIiAqKkqdO3fWnDlzQtP8fr/mzJmj7t2721jZickYo1tuuUXTpk3T559/rmbNmh31PcuWLZMkpaenh7m6mmf//v1at26d0tPT1blzZ3m93jLH8po1a7R582aO5SqYPHmy6tevrwEDBhxxOY7f49OsWTOlpaWVOW5zcnK0cOHC0HHbvXt3ZWVlacmSJaFlPv/8c/n9/lBIxeEFA9Ivv/yi2bNnq06dOkd9z7Jly+RyucqdIobK2bp1q3bv3h36vcAxXD1efvllde7cWR07djzqshzDBx3tu1llvj90795dK1euLBP2g39wadu2bWR2pLSIDxVxknrrrbdMdHS0mTJlivnxxx/N6NGjTUpKSpkRPFA5f/zjH01ycrKZN2+e2b59e+iRl5dnjDFm7dq1ZuLEiea7774zGzZsMB9++KFp3ry56dGjh82VnxjuuusuM2/ePLNhwwbz9ddfm169epm6deuanTt3GmOMuemmm0zjxo3N559/br777jvTvXt30717d5urPvEUFxebxo0bm3HjxpWZzvFbNfv27TPff/+9+f77740k88QTT5jvv/8+NLraI488YlJSUsyHH35oVqxYYQYNGmSaNWtmDhw4EFpH3759zemnn24WLlxovvrqK9OyZUszbNgwu3bJUY7UvoWFheaSSy4xjRo1MsuWLSvzezk4ItU333xjnnzySbNs2TKzbt068/rrr5t69eqZESNG2LxnznGkNt63b5+5++67zYIFC8yGDRvM7NmzzRlnnGFatmxp8vPzQ+vgGD68o/2OMMaY7OxsExcXZ1544YVy7+cYPrKjfTcz5ujfH4qKisxpp51mevfubZYtW2Y+++wzU69ePXPvvffasUuGkBRBzzzzjGncuLGJiooyXbt2Nd9++63dJZ2QJFX4mDx5sjHGmM2bN5sePXqY2rVrm+joaHPKKaeYe+65x2RnZ9tb+Ali6NChJj093URFRZmGDRuaoUOHmrVr14bmHzhwwNx8882mVq1aJi4uzlx66aVm+/btNlZ8YpoxY4aRZNasWVNmOsdv1cydO7fC3wsjR440xgSGAR8/frxJTU010dHRpmfPnuXafvfu3WbYsGEmISHBJCUlmd///vdm3759NuyN8xypfTds2HDY38tz5841xhizZMkS061bN5OcnGxiYmJMmzZtzEMPPVTmC/7J7khtnJeXZ3r37m3q1atnvF6vadKkibnxxhvL/aGVY/jwjvY7whhjXnrpJRMbG2uysrLKvZ9j+MiO9t3MmMp9f9i4caPp16+fiY2NNXXr1jV33XWX8fl8Ed6bAMsYY8LUSQUAAAAAJxyuSQIAAACAUghJAAAAAFAKIQkAAAAASiEkAQAAAEAphCQAAAAAKIWQBAAAAAClEJIAAAAAoBRCEgAAAACUQkgCAOAILMvS9OnT7S4DABBBhCQAgGNdd911siyr3KNv3752lwYAqME8dhcAAMCR9O3bV5MnTy4zLTo62qZqAAAnA3qSAACOFh0drbS0tDKPWrVqSQqcCvfCCy+oX79+io2NVfPmzfXee++Vef/KlSv1u9/9TrGxsapTp45Gjx6t/fv3l1nmlVdeUbt27RQdHa309HTdcsstZebv2rVLl156qeLi4tSyZUt99NFH4d1pAICtCEkAgBPa+PHjNWTIEC1fvlzDhw/XVVddpdWrV0uScnNz1adPH9WqVUuLFy/Wu+++q9mzZ5cJQS+88ILGjBmj0aNHa+XKlfroo490yimnlNnGAw88oCuvvFIrVqxQ//79NXz4cO3Zsyei+wkAiBzLGGPsLgIAgIpcd911ev311xUTE1Nm+l/+8hf95S9/kWVZuummm/TCCy+E5p111lk644wz9Pzzz+vf//63xo0bpy1btig+Pl6S9Mknn2jgwIHatm2bUlNT1bBhQ/3+97/XP/7xjwprsCxLf/3rX/X3v/9dUiB4JSQk6NNPP+XaKACoobgmCQDgaBdeeGGZECRJtWvXDj3v3r17mXndu3fXsmXLJEmrV69Wx44dQwFJks455xz5/X6tWbNGlmVp27Zt6tmz5xFr6NChQ+h5fHy8kpKStHPnzqruEgDA4QhJAABHi4+PL3f6W3WJjY2t1HJer7fMa8uy5Pf7w1ESAMABuCYJAHBC+/bbb8u9btOmjSSpTZs2Wr58uXJzc0Pzv/76a7lcLp166qlKTExU06ZNNWfOnIjWDABwNnqSAACOVlBQoB07dpSZ5vF4VLduXUnSu+++qy5duujcc8/VG2+8oUWLFunll1+WJA0fPlx/+9vfNHLkSE2YMEG//fabbr31Vl177bVKTU2VJE2YMEE33XST6tevr379+mnfvn36+uuvdeutt0Z2RwEAjkFIAgA42meffab09PQy00499VT99NNPkgIjz7311lu6+eablZ6erjfffFNt27aVJMXFxWnGjBm6/fbbdeaZZyouLk5DhgzRE088EVrXyJEjlZ+fryeffFJ333236tatq8svvzxyOwgAcBxGtwMAnLAsy9K0adM0ePBgu0sBANQgXJMEAAAAAKUQkgAAAACgFK5JAgCcsDhjHAAQDvQkAQAAAEAphCQAAAAAKIWQBAAAAAClEJIAAAAAoBRCEgAAAACUQkgCAAAAgFIISQAAAABQCiEJAAAAAEr5/zI7wmyl4U8jAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 220
        },
        "id": "aeed9704",
        "outputId": "c197e24b-6aa5-4a85-8916-27af4f5faeb9"
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.scatter(y_test, y_pred, alpha=0.6)\n",
        "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--')\n",
        "plt.xlabel(\"Actual\")\n",
        "plt.ylabel(\"Predicted\")\n",
        "plt.title(\"Actual vs Predicted Values\")\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2929320232.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bce8b0ea",
        "outputId": "5ef4bb02-51e5-4a8c-b50c-68fdc01092ba"
      },
      "source": [
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\n=== Evaluasi Regresi ===\")\n",
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Evaluasi Regresi ===\n",
            "Mean Squared Error (MSE): 77.6729\n",
            "Mean Absolute Error (MAE): 5.5899\n",
            "R² Score: 0.3456\n"
          ]
        }
      ]
    }
  ]
}